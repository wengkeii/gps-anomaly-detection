{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50341e8-bda5-465e-92bf-746e8516497f",
   "metadata": {},
   "source": [
    "# 1. Load Microsoft Geolife Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0868b067-c9d9-41ad-a7d2-8676f35d4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main directory \n",
    "main_directory = 'C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff98efc-8a2b-4966-b4a3-9e051ab6a0cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.1 Load Labelled Dataset (labels.txt & Trajectory folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ca8e663-2131-49d7-901e-18cdd7fc6417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      User           Start Time             End Time Transportation Mode\n",
      "0      010  2007/06/26 11:32:29  2007/06/26 11:40:29                 Bus\n",
      "1      010  2008/03/28 14:52:54  2008/03/28 15:59:59               Train\n",
      "2      010  2008/03/28 16:00:00  2008/03/28 22:02:00               Train\n",
      "3      010  2008/03/29 01:27:50  2008/03/29 15:59:59               Train\n",
      "4      010  2008/03/29 16:00:00  2008/03/30 15:59:59               Train\n",
      "...    ...                  ...                  ...                 ...\n",
      "14689  179  2008/11/17 06:59:58  2008/11/17 07:06:16                 Bus\n",
      "14690  179  2008/11/17 07:06:16  2008/11/17 07:14:32                Walk\n",
      "14691  179  2008/11/29 01:58:05  2008/11/29 02:01:39                 Bus\n",
      "14692  179  2008/11/29 02:01:39  2008/11/29 02:07:57                Walk\n",
      "14693  179  2008/11/29 02:07:57  2008/11/29 02:43:37               Train\n",
      "\n",
      "[14694 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "# Initialize start_end_traj DataFrame \n",
    "start_end_traj = pd.DataFrame()\n",
    "\n",
    "# Loop through each user directory\n",
    "for user_id in range(182):\n",
    "    user_folder = os.path.join(main_directory, f'{user_id:03}', 'Trajectory')\n",
    "    labels_file = os.path.join(main_directory, f'{user_id:03}', 'labels.txt')\n",
    "    \n",
    "    # Check if labels.txt exists in current user folder\n",
    "    if os.path.exists(labels_file):\n",
    "        # Read the labels.txt file\n",
    "        user_labels = pd.read_csv(labels_file, delimiter='\\t')\n",
    "        \n",
    "        # Remove rows with 'boat' or 'airplane' in Transportation Mode\n",
    "        user_labels = user_labels[~user_labels['Transportation Mode'].isin(['boat', 'airplane'])]\n",
    "        \n",
    "        # Consolidate transport modes\n",
    "        mode_mapping = {\n",
    "            'car': 'Car', 'taxi': 'Car',\n",
    "            'train': 'Train', 'subway': 'Train',\n",
    "            'walk': 'Walk', 'run': 'Walk',\n",
    "            'bike': 'Bike', 'motorcycle': 'Bike',\n",
    "            'bus': 'Bus'\n",
    "        }\n",
    "        \n",
    "        # Apply mode mapping to Transportation Mode column\n",
    "        user_labels['Transportation Mode'] = user_labels['Transportation Mode'].map(mode_mapping)\n",
    "        \n",
    "        # Add column for user ID\n",
    "        user_labels['User'] = f'{user_id:03}'\n",
    "        \n",
    "        # Append to start_end_traj DataFrame\n",
    "        start_end_traj = pd.concat([start_end_traj, user_labels], ignore_index=True)\n",
    "\n",
    "# Reorder columns \n",
    "start_end_traj = start_end_traj[['User', 'Start Time', 'End Time', 'Transportation Mode']]\n",
    "\n",
    "# Print start_end_traj DataFrame\n",
    "print(start_end_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac564470-a2ee-41b8-a355-9c5e4e842700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        User Transportation Mode           Date-Time  Latitude(deg)  \\\n",
      "0        010               Train 2008-03-28 14:54:40      39.894178   \n",
      "1        010               Train 2008-03-28 14:55:14      39.894505   \n",
      "2        010               Train 2008-03-28 14:56:13      39.894953   \n",
      "3        010               Train 2008-03-28 14:57:12      39.894600   \n",
      "4        010               Train 2008-03-28 14:58:11      39.889622   \n",
      "...      ...                 ...                 ...            ...   \n",
      "5496246  179               Train 2008-11-29 02:29:29      40.029320   \n",
      "5496247  179               Train 2008-11-29 02:29:31      40.029111   \n",
      "5496248  179               Train 2008-11-29 02:29:33      40.028904   \n",
      "5496249  179               Train 2008-11-29 02:29:35      40.028697   \n",
      "5496250  179               Train 2008-11-29 02:43:37      39.967705   \n",
      "\n",
      "         Longitude(deg)  Altitude(ft)  \n",
      "0            116.318200        -777.0  \n",
      "1            116.321132        -777.0  \n",
      "2            116.326452        -777.0  \n",
      "3            116.332542        -777.0  \n",
      "4            116.337040        -777.0  \n",
      "...                 ...           ...  \n",
      "5496246      116.411975         289.0  \n",
      "5496247      116.411963         275.0  \n",
      "5496248      116.411962         274.0  \n",
      "5496249      116.411961         274.0  \n",
      "5496250      116.412042         333.0  \n",
      "\n",
      "[5496251 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize empty lists to store DataFrames for each user's trajectory data and labels\n",
    "all_data = []\n",
    "all_users_data = []\n",
    "\n",
    "# Loop through each user directory\n",
    "for user_folder in os.listdir(main_directory):\n",
    "    user_folder_path = os.path.join(main_directory, user_folder)\n",
    "\n",
    "    # Define paths for labels.txt and Trajectory folder\n",
    "    labels_file_path = os.path.join(user_folder_path, 'labels.txt')\n",
    "    trajectory_folder_path = os.path.join(user_folder_path, 'Trajectory')\n",
    "    \n",
    "    # Check if the path is a directory and contains labels.txt\n",
    "    if os.path.isdir(user_folder_path) and os.path.exists(labels_file_path):\n",
    "        # Read the labels.txt file\n",
    "        labels_df = pd.read_csv(labels_file_path, sep='\\t')\n",
    "        # Add a column for user ID\n",
    "        labels_df['User'] = user_folder\n",
    "        # Append the DataFrame to the list of labels data\n",
    "        all_users_data.append(labels_df)\n",
    "        \n",
    "        # Check if the user folder contains the Trajectory folder\n",
    "        if os.path.exists(trajectory_folder_path) and os.path.isdir(trajectory_folder_path):\n",
    "            # Initialize an empty list to store DataFrames for each PLT file\n",
    "            user_data = []\n",
    "            # Iterate through each PLT file in the Trajectory folder\n",
    "            for plt_file in os.listdir(trajectory_folder_path):\n",
    "                plt_file_path = os.path.join(trajectory_folder_path, plt_file)\n",
    "                # Read the PLT file into a DataFrame\n",
    "                df = pd.read_csv(plt_file_path, skiprows=6, header=None, \n",
    "                                 names=['Latitude(deg)', 'Longitude(deg)', 'All set to 0', 'Altitude(ft)', 'No of days since 12/30/1899', 'Date', 'Time'], \n",
    "                                 usecols=[0, 1, 3, 5, 6])  # Skip Column 2 'All set to 0' & Column 4 'No of days since 12/30/1899'\n",
    "                # Append the DataFrame to the list of user data\n",
    "                user_data.append(df)\n",
    "            # Concatenate all DataFrames for user into a single DataFrame\n",
    "            user_df = pd.concat(user_data, ignore_index=True)\n",
    "            # Add column for user ID\n",
    "            user_df['User'] = user_folder\n",
    "            # Append the DataFrame for the user to the list of all data\n",
    "            all_data.append(user_df)\n",
    "\n",
    "# Concatenate all DataFrames for each user into a single DataFrame\n",
    "all_data_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Merge Date and Time columns to create a Date-Time column\n",
    "all_data_df['Date-Time'] = pd.to_datetime(all_data_df['Date'] + ' ' + all_data_df['Time'])\n",
    "# Drop the Date & Time columns \n",
    "all_data_df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "# Reorder the columns\n",
    "all_data_df = all_data_df[['User', 'Latitude(deg)', 'Longitude(deg)', 'Altitude(ft)', 'Date-Time']]\n",
    "\n",
    "# Concatenate all DataFrames for different users into a single DataFrame\n",
    "all_labels_df = pd.concat(all_users_data, ignore_index=True)\n",
    "\n",
    "# Remove records for \"boat\" and \"airplane\" \n",
    "all_labels_df = all_labels_df[~all_labels_df['Transportation Mode'].isin(['boat', 'airplane'])]\n",
    "\n",
    "# Consolidate transport modes\n",
    "mode_mapping = {\n",
    "    'car': 'Car', 'taxi': 'Car',\n",
    "    'train': 'Train', 'subway': 'Train',\n",
    "    'walk': 'Walk', 'run': 'Walk',\n",
    "    'bike': 'Bike', 'motorcycle': 'Bike',\n",
    "    'bus': 'Bus'\n",
    "}\n",
    "\n",
    "# Apply mode mapping to Transportation Mode column\n",
    "all_labels_df['Transportation Mode'] = all_labels_df['Transportation Mode'].map(mode_mapping)\n",
    "\n",
    "# Ensure the Date-Time columns are in datetime format\n",
    "all_data_df['Date-Time'] = pd.to_datetime(all_data_df['Date-Time'])\n",
    "all_labels_df['Start Time'] = pd.to_datetime(all_labels_df['Start Time'])\n",
    "all_labels_df['End Time'] = pd.to_datetime(all_labels_df['End Time'])\n",
    "\n",
    "# Initialize empty list to store filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Iterate through each user\n",
    "for user in all_data_df['User'].unique():\n",
    "    user_data = all_data_df[all_data_df['User'] == user]\n",
    "    user_labels = all_labels_df[all_labels_df['User'] == user]\n",
    "    for _, label in user_labels.iterrows():\n",
    "        # Filter the user_data based on Start Time and End Time\n",
    "        filtered_user_data = user_data[(user_data['Date-Time'] >= label['Start Time']) & \n",
    "                                       (user_data['Date-Time'] <= label['End Time'])]\n",
    "        if not filtered_user_data.empty:\n",
    "            filtered_user_data = filtered_user_data.copy()  # To avoid SettingWithCopyWarning\n",
    "            filtered_user_data.loc[:, 'Transportation Mode'] = label['Transportation Mode']\n",
    "            filtered_data.append(filtered_user_data)\n",
    "\n",
    "# Concatenate all filtered data into a single DataFrame\n",
    "labelled_df = pd.concat(filtered_data, ignore_index=True)\n",
    "\n",
    "# Reorder columns\n",
    "labelled_df = labelled_df[['User', 'Transportation Mode', 'Date-Time', 'Latitude(deg)', 'Longitude(deg)', 'Altitude(ft)']]\n",
    "\n",
    "# Print labelled_df DataFrame\n",
    "print(labelled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b165c6-25db-4e17-98c3-a88458fdbfd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.2 Combine Labelled Dataset with Transport Mode & Start and End Points (labelled_trajectories.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d65cb43-de79-468c-8976-e04a3e979eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        User Transportation Mode           Date-Time  Latitude(deg)  \\\n",
      "0        010               Train 2008-03-28 14:54:40      39.894178   \n",
      "1        010               Train 2008-03-28 14:55:14      39.894505   \n",
      "2        010               Train 2008-03-28 14:56:13      39.894953   \n",
      "3        010               Train 2008-03-28 14:57:12      39.894600   \n",
      "4        010               Train 2008-03-28 14:58:11      39.889622   \n",
      "...      ...                 ...                 ...            ...   \n",
      "5496246  179               Train 2008-11-29 02:29:29      40.029320   \n",
      "5496247  179               Train 2008-11-29 02:29:31      40.029111   \n",
      "5496248  179               Train 2008-11-29 02:29:33      40.028904   \n",
      "5496249  179               Train 2008-11-29 02:29:35      40.028697   \n",
      "5496250  179               Train 2008-11-29 02:43:37      39.967705   \n",
      "\n",
      "         Longitude(deg)  Altitude(ft)          Start Time            End Time  \\\n",
      "0            116.318200        -777.0 2008-03-28 14:52:54 2008-03-28 15:59:59   \n",
      "1            116.321132        -777.0 2008-03-28 14:52:54 2008-03-28 15:59:59   \n",
      "2            116.326452        -777.0 2008-03-28 14:52:54 2008-03-28 15:59:59   \n",
      "3            116.332542        -777.0 2008-03-28 14:52:54 2008-03-28 15:59:59   \n",
      "4            116.337040        -777.0 2008-03-28 14:52:54 2008-03-28 15:59:59   \n",
      "...                 ...           ...                 ...                 ...   \n",
      "5496246      116.411975         289.0 2008-11-29 02:07:57 2008-11-29 02:43:37   \n",
      "5496247      116.411963         275.0 2008-11-29 02:07:57 2008-11-29 02:43:37   \n",
      "5496248      116.411962         274.0 2008-11-29 02:07:57 2008-11-29 02:43:37   \n",
      "5496249      116.411961         274.0 2008-11-29 02:07:57 2008-11-29 02:43:37   \n",
      "5496250      116.412042         333.0 2008-11-29 02:07:57 2008-11-29 02:43:37   \n",
      "\n",
      "         Start Latitude(deg)  Start Longitude(deg)  End Latitude(deg)  \\\n",
      "0                  39.894178            116.318200          39.506952   \n",
      "1                  39.894178            116.318200          39.506952   \n",
      "2                  39.894178            116.318200          39.506952   \n",
      "3                  39.894178            116.318200          39.506952   \n",
      "4                  39.894178            116.318200          39.506952   \n",
      "...                      ...                   ...                ...   \n",
      "5496246            40.069518            116.313381          39.967705   \n",
      "5496247            40.069518            116.313381          39.967705   \n",
      "5496248            40.069518            116.313381          39.967705   \n",
      "5496249            40.069518            116.313381          39.967705   \n",
      "5496250            40.069518            116.313381          39.967705   \n",
      "\n",
      "         End Longitude(deg)  \n",
      "0                116.707353  \n",
      "1                116.707353  \n",
      "2                116.707353  \n",
      "3                116.707353  \n",
      "4                116.707353  \n",
      "...                     ...  \n",
      "5496246          116.412042  \n",
      "5496247          116.412042  \n",
      "5496248          116.412042  \n",
      "5496249          116.412042  \n",
      "5496250          116.412042  \n",
      "\n",
      "[5496251 rows x 12 columns]\n",
      "Trajectories with mode of transport labelled saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\labelled_trajectories.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize empty lists to store DataFrames for each user's trajectory data and labels\n",
    "all_data = []\n",
    "all_users_data = []\n",
    "\n",
    "# Loop through each user directory\n",
    "for user_folder in os.listdir(main_directory):\n",
    "    user_folder_path = os.path.join(main_directory, user_folder)\n",
    "\n",
    "    # Define paths for labels.txt and Trajectory folder\n",
    "    labels_file_path = os.path.join(user_folder_path, 'labels.txt')\n",
    "    trajectory_folder_path = os.path.join(user_folder_path, 'Trajectory')\n",
    "    \n",
    "    # Check if the path is a directory and contains labels.txt\n",
    "    if os.path.isdir(user_folder_path) and os.path.exists(labels_file_path):\n",
    "        # Read labels.txt file\n",
    "        labels_df = pd.read_csv(labels_file_path, sep='\\t')\n",
    "        # Add column for user ID\n",
    "        labels_df['User'] = user_folder\n",
    "        # Append DataFrame to the list of labels data\n",
    "        all_users_data.append(labels_df)\n",
    "        \n",
    "        # Check if user folder contains the Trajectory folder\n",
    "        if os.path.exists(trajectory_folder_path) and os.path.isdir(trajectory_folder_path):\n",
    "            # Initialize an empty list to store DataFrames for each PLT file\n",
    "            user_data = []\n",
    "            # Iterate through each PLT file in the Trajectory folder\n",
    "            for plt_file in os.listdir(trajectory_folder_path):\n",
    "                plt_file_path = os.path.join(trajectory_folder_path, plt_file)\n",
    "                # Read PLT file into a DataFrame\n",
    "                df = pd.read_csv(plt_file_path, skiprows=6, header=None, \n",
    "                                 names=['Latitude(deg)', 'Longitude(deg)', 'All set to 0', 'Altitude(ft)', 'No of days since 12/30/1899', 'Date', 'Time'], \n",
    "                                 usecols=[0, 1, 3, 5, 6])  # Skip Column 2 'All set to 0' & Column 4 'No of days since 12/30/1899'\n",
    "                # Append the DataFrame to the list of user data\n",
    "                user_data.append(df)\n",
    "            # Concatenate all DataFrames for the user into a single DataFrame\n",
    "            user_df = pd.concat(user_data, ignore_index=True)\n",
    "            # Add column for user ID\n",
    "            user_df['User'] = user_folder\n",
    "            # Append DataFrame for user to the list of all data\n",
    "            all_data.append(user_df)\n",
    "\n",
    "# Concatenate all DataFrames for each user into a single DataFrame\n",
    "all_data_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Merge Date and Time columns to create a Date-Time column\n",
    "all_data_df['Date-Time'] = pd.to_datetime(all_data_df['Date'] + ' ' + all_data_df['Time'])\n",
    "# Drop Date & Time columns \n",
    "all_data_df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "\n",
    "# Concatenate all DataFrames for different users into a single DataFrame\n",
    "all_labels_df = pd.concat(all_users_data, ignore_index=True)\n",
    "\n",
    "# Remove records for \"boat\" and \"airplane\" \n",
    "all_labels_df = all_labels_df[~all_labels_df['Transportation Mode'].isin(['boat', 'airplane'])]\n",
    "\n",
    "# Consolidate transport modes\n",
    "mode_mapping = {\n",
    "    'car': 'Car', 'taxi': 'Car',\n",
    "    'train': 'Train', 'subway': 'Train',\n",
    "    'walk': 'Walk', 'run': 'Walk',\n",
    "    'bike': 'Bike', 'motorcycle': 'Bike',\n",
    "    'bus': 'Bus'\n",
    "}\n",
    "\n",
    "# Apply mode mapping to Transportation Mode column\n",
    "all_labels_df['Transportation Mode'] = all_labels_df['Transportation Mode'].map(mode_mapping)\n",
    "\n",
    "# Ensure the Date-Time columns are in datetime format\n",
    "all_data_df['Date-Time'] = pd.to_datetime(all_data_df['Date-Time'])\n",
    "all_labels_df['Start Time'] = pd.to_datetime(all_labels_df['Start Time'])\n",
    "all_labels_df['End Time'] = pd.to_datetime(all_labels_df['End Time'])\n",
    "\n",
    "# Initialize an empty list to store filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Iterate through each user\n",
    "for user in all_data_df['User'].unique():\n",
    "    user_data = all_data_df[all_data_df['User'] == user]\n",
    "    user_labels = all_labels_df[all_labels_df['User'] == user]\n",
    "    for _, label in user_labels.iterrows():\n",
    "        # Filter the user_data based on Start Time and End Time\n",
    "        filtered_user_data = user_data[(user_data['Date-Time'] >= label['Start Time']) & \n",
    "                                       (user_data['Date-Time'] <= label['End Time'])]\n",
    "        if not filtered_user_data.empty:\n",
    "            filtered_user_data = filtered_user_data.copy()  # To avoid SettingWithCopyWarning\n",
    "            filtered_user_data.loc[:, 'Transportation Mode'] = label['Transportation Mode']\n",
    "            filtered_user_data.loc[:, 'Start Time'] = label['Start Time']\n",
    "            filtered_user_data.loc[:, 'End Time'] = label['End Time']\n",
    "            filtered_user_data.loc[:, 'Start Latitude(deg)'] = filtered_user_data['Latitude(deg)'].iloc[0]\n",
    "            filtered_user_data.loc[:, 'Start Longitude(deg)'] = filtered_user_data['Longitude(deg)'].iloc[0]\n",
    "            filtered_user_data.loc[:, 'End Latitude(deg)'] = filtered_user_data['Latitude(deg)'].iloc[-1]\n",
    "            filtered_user_data.loc[:, 'End Longitude(deg)'] = filtered_user_data['Longitude(deg)'].iloc[-1]\n",
    "\n",
    "            filtered_data.append(filtered_user_data)\n",
    "\n",
    "# Concatenate all filtered data into a single DataFrame\n",
    "labelled_df = pd.concat(filtered_data, ignore_index=True)\n",
    "\n",
    "# Reorder columns\n",
    "labelled_df = labelled_df[['User', 'Transportation Mode', 'Date-Time', 'Latitude(deg)', 'Longitude(deg)', 'Altitude(ft)', 'Start Time', 'End Time',\n",
    "                           'Start Latitude(deg)', 'Start Longitude(deg)', 'End Latitude(deg)', 'End Longitude(deg)']]\n",
    "\n",
    "# Print labelled_df DataFrame\n",
    "print(labelled_df)\n",
    "\n",
    "# Save labelled_df to labelled_trajectories.csv file\n",
    "output_file = os.path.join(main_directory, 'labelled_trajectories.csv')\n",
    "labelled_df.to_csv(output_file, index=False)\n",
    "print(f'Trajectories with mode of transport labelled saved to {output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573d79d-3d8f-4524-8cdb-663c7d3c518b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.3 Combine Labelled Dataset to form Trajectories (labelled_trajectories_geopandas.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76501f28-63d0-4ede-94a7-557096e719a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wengk.WK\\AppData\\Local\\Temp\\ipykernel_19636\\2321226939.py:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  trajectories = labelled_df.groupby(['User', 'Start Time', 'End Time'], group_keys=False).apply(create_trajectory).reset_index(name='Trajectory')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      User                                         Trajectory  \\\n",
      "0       10  LINESTRING (116.31820 39.89418, 116.32113 39.8...   \n",
      "1       10  LINESTRING (116.71495 39.50293, 116.72614 39.4...   \n",
      "2       10  LINESTRING (116.95947 36.66328, 116.95627 36.6...   \n",
      "3       10  LINESTRING (109.61987 34.49713, 109.60540 34.4...   \n",
      "4       10  LINESTRING (95.45776 41.14720, 95.44490 41.153...   \n",
      "...    ...                                                ...   \n",
      "9563   179  LINESTRING (116.31263 40.07015, 116.31261 40.0...   \n",
      "9564   179  LINESTRING (116.29891 40.08890, 116.29895 40.0...   \n",
      "9565   179  LINESTRING (116.30685 40.07311, 116.30683 40.0...   \n",
      "9566   179  LINESTRING (116.31381 40.07024, 116.31375 40.0...   \n",
      "9567   179  LINESTRING (116.31338 40.06952, 116.31352 40.0...   \n",
      "\n",
      "     Transportation Mode          Start Time            End Time  \\\n",
      "0                  Train 2008-03-28 14:52:54 2008-03-28 15:59:59   \n",
      "1                  Train 2008-03-28 16:00:00 2008-03-28 22:02:00   \n",
      "2                  Train 2008-03-29 01:27:50 2008-03-29 15:59:59   \n",
      "3                  Train 2008-03-29 16:00:00 2008-03-30 15:59:59   \n",
      "4                  Train 2008-03-30 16:00:00 2008-03-31 03:13:11   \n",
      "...                  ...                 ...                 ...   \n",
      "9563                 Bus 2008-11-17 06:59:58 2008-11-17 07:06:16   \n",
      "9564                Walk 2008-11-17 07:06:16 2008-11-17 07:14:32   \n",
      "9565                 Bus 2008-11-29 01:58:05 2008-11-29 02:01:39   \n",
      "9566                Walk 2008-11-29 02:01:39 2008-11-29 02:07:57   \n",
      "9567               Train 2008-11-29 02:07:57 2008-11-29 02:43:37   \n",
      "\n",
      "      Start Longitude(deg)  Start Latitude(deg)  End Longitude(deg)  \\\n",
      "0               116.318200            39.894178          116.707353   \n",
      "1               116.714948            39.502930          116.988268   \n",
      "2               116.959467            36.663282          109.629697   \n",
      "3               109.619872            34.497127           95.465557   \n",
      "4                95.457762            41.147205           87.576190   \n",
      "...                    ...                  ...                 ...   \n",
      "9563            116.312632            40.070155          116.298911   \n",
      "9564            116.298911            40.088898          116.304162   \n",
      "9565            116.306853            40.073108          116.313808   \n",
      "9566            116.313808            40.070242          116.317385   \n",
      "9567            116.313381            40.069518          116.412042   \n",
      "\n",
      "      End Latitude(deg)  Distance(km)  Duration(hr)  Speed(km/h)  \n",
      "0             39.506952     62.604343      1.118056    55.993947  \n",
      "1             36.671463    409.116643      6.033333    67.809388  \n",
      "2             34.490502   1071.454161     14.535833    73.711230  \n",
      "3             41.137635   1588.784518     23.999722    66.200121  \n",
      "4             43.697033    772.508295     11.219722    68.852711  \n",
      "...                 ...           ...           ...          ...  \n",
      "9563          40.088898      2.657616      0.105000    25.310631  \n",
      "9564          40.087012      0.729351      0.137778     5.293677  \n",
      "9565          40.070242      2.033459      0.059444    34.207728  \n",
      "9566          40.070652      0.534142      0.105000     5.087066  \n",
      "9567          39.967705     18.243287      0.594444    30.689642  \n",
      "\n",
      "[9568 rows x 12 columns]\n",
      "GeoDataFrame of Labelled Dataset saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\labelled_trajectories_geopandas.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, Point\n",
    "from math import radians, cos, sin, sqrt, atan2\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load the labelled DataFrame\n",
    "labelled_file = os.path.join(main_directory, 'labelled_trajectories.csv')\n",
    "labelled_df = pd.read_csv(labelled_file, parse_dates=['Date-Time'])\n",
    "\n",
    "# Ensure 'Date-Time' is in datetime format\n",
    "labelled_df['Date-Time'] = pd.to_datetime(labelled_df['Date-Time'])\n",
    "labelled_df['Start Time'] = pd.to_datetime(labelled_df['Start Time'])\n",
    "labelled_df['End Time'] = pd.to_datetime(labelled_df['End Time'])\n",
    "\n",
    "# Sort dataframe by User and Start Time\n",
    "labelled_df = labelled_df.sort_values(by=['User', 'Start Time'])\n",
    "\n",
    "# Function to create trajectories\n",
    "def create_trajectory(group):\n",
    "    if len(group) > 1: \n",
    "        return LineString(zip(group['Longitude(deg)'], group['Latitude(deg)']))\n",
    "    else:\n",
    "        return None  \n",
    "\n",
    "# Extract start and end points\n",
    "start_points = labelled_df.groupby(['User', 'Start Time', 'End Time']).first().reset_index()\n",
    "end_points = labelled_df.groupby(['User', 'Start Time', 'End Time']).last().reset_index()\n",
    "\n",
    "# Group by User, Start Time & End Time and create trajectories\n",
    "trajectories = labelled_df.groupby(['User', 'Start Time', 'End Time'], group_keys=False).apply(create_trajectory).reset_index(name='Trajectory')\n",
    "\n",
    "# Filter out None trajectories\n",
    "trajectories = trajectories[trajectories['Trajectory'].notnull()]\n",
    "\n",
    "# Merge trajectories back to the original dataframe (keep only first occurrence of each trajectories)\n",
    "labelled_df = labelled_df.drop(columns=['Longitude(deg)', 'Latitude(deg)'])\n",
    "labelled_df = pd.merge(labelled_df.drop_duplicates(subset=['User', 'Start Time', 'End Time']), trajectories, on=['User', 'Start Time', 'End Time'])\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(labelled_df, geometry='Trajectory')\n",
    "\n",
    "# Define the Haversine formula\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of the Earth in km\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "    \n",
    "# Calculate Distance using Haversine formula\n",
    "distances = []\n",
    "for index, row in gdf.iterrows():\n",
    "    distance = 0\n",
    "    if isinstance(row['Trajectory'], LineString):\n",
    "        coords = list(row['Trajectory'].coords)\n",
    "        for i in range(len(coords) - 1):\n",
    "            lon1, lat1 = coords[i]\n",
    "            lon2, lat2 = coords[i + 1]\n",
    "            distance += calculate_distance(lat1, lon1, lat2, lon2)\n",
    "    distances.append(distance)\n",
    "gdf['Distance(km)'] = distances\n",
    "\n",
    "# Calculate Duration in hour and Speed in km/h\n",
    "gdf['Duration(hr)'] = (gdf['End Time'] - gdf['Start Time']).dt.total_seconds() / 3600\n",
    "gdf['Speed(km/h)'] = gdf['Distance(km)'] / gdf['Duration(hr)']\n",
    "\n",
    "# View the trajectories \n",
    "print(gdf[['User', 'Trajectory', 'Transportation Mode', 'Start Time', 'End Time', 'Start Longitude(deg)', \n",
    "           'Start Latitude(deg)', 'End Longitude(deg)', 'End Latitude(deg)', 'Distance(km)', 'Duration(hr)', 'Speed(km/h)']])\n",
    "\n",
    "# Save the GeoDataFrame to labelled_trajectories_geopandas.csv file\n",
    "output_file_path = os.path.join(main_directory, 'labelled_trajectories_geopandas.csv')\n",
    "gdf.to_csv(output_file_path, index=False)\n",
    "print(f\"GeoDataFrame of Labelled Dataset saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5860f34-44e4-4a29-96b5-c1d49835b092",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.4 Load Unlabelled Dataset - No Transport Mode and Start & End Points (unlabelled_trajectories.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beed56e0-8225-4d72-9bdf-c70dd5e58855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         User           Date-Time  Latitude(deg)  Longitude(deg)  Altitude(ft)\n",
      "0         000 2008-10-23 02:53:04      39.984702      116.318417    492.000000\n",
      "1         000 2008-10-23 02:53:10      39.984683      116.318450    492.000000\n",
      "2         000 2008-10-23 02:53:15      39.984686      116.318417    492.000000\n",
      "3         000 2008-10-23 02:53:20      39.984688      116.318385    492.000000\n",
      "4         000 2008-10-23 02:53:25      39.984655      116.318263    492.000000\n",
      "...       ...                 ...            ...             ...           ...\n",
      "12359609  181 2008-03-14 03:39:56      40.914867      111.710500   3802.493438\n",
      "12359610  181 2008-03-14 03:41:17      40.914267      111.710333   3795.931759\n",
      "12359611  181 2008-03-14 03:43:02      40.912467      111.710667   3795.931759\n",
      "12359612  181 2008-03-14 03:43:28      40.911517      111.711317   3779.527559\n",
      "12359613  181 2008-03-14 03:43:40      40.910933      111.711617   3802.493438\n",
      "\n",
      "[12359614 rows x 5 columns]\n",
      "Unlabelled trajectories saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\unlabelled_trajectories.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize empty list to store DataFrames from each user's Trajectory folder\n",
    "dataframes = []\n",
    "\n",
    "# # Loop through each user directory (000 to 181)\n",
    "for user_folder in range(182):\n",
    "    user_folder_path = os.path.join(main_directory, f'{user_folder:03d}')\n",
    "    labels_file_path = os.path.join(user_folder_path, 'labels.txt')\n",
    "    trajectory_folder_path = os.path.join(user_folder_path, 'Trajectory')\n",
    "    \n",
    "    # Check if labels.txt does not exist (unlabelled data)\n",
    "    if not os.path.exists(labels_file_path):\n",
    "        # Process Trajectory folder\n",
    "        for trajectory_file in os.listdir(trajectory_folder_path):\n",
    "            if trajectory_file.endswith('.plt'):\n",
    "                trajectory_file_path = os.path.join(trajectory_folder_path, trajectory_file)\n",
    "                # Read the trajectory file, skipping the first 6 lines of metadata\n",
    "                df = pd.read_csv(trajectory_file_path, skiprows=6, header=None, \n",
    "                                 names=['Latitude(deg)', 'Longitude(deg)', 'Zero1', 'Altitude(ft)', 'Date Days', 'Date', 'Time'])\n",
    "                df['User'] = f'{user_folder:03d}'\n",
    "                df['Date-Time'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "                df = df[['User', 'Date-Time', 'Latitude(deg)', 'Longitude(deg)', 'Altitude(ft)']]\n",
    "                dataframes.append(df)\n",
    "\n",
    "# Combine all dataframes into a single dataframe\n",
    "unlabelled_trajectories_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Print unlabelled_trajectories_df DataFrame\n",
    "print(unlabelled_trajectories_df)\n",
    "\n",
    "# Save unlabelled_trajectories_df DataFrame to unlabelled_trajectories file\n",
    "output_file_path = os.path.join(main_directory, 'unlabelled_trajectories.csv')\n",
    "unlabelled_trajectories_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Unlabelled trajectories saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d665f2-2310-4d99-b012-bd90c546d05b",
   "metadata": {},
   "source": [
    "# 2. Model to Predict Start & End Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a3b27-be88-4688-a72b-374a2296bff5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.1 Train & Evaluate Model using labelled_trajectories - Random Forest Regressor (Start: 88% & End: 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11b878e-57d9-497d-8c76-51d4bd6ff4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Start points regressor model saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\start_points_regressor.pkl\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "End points regressor model saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\end_points_regressor.pkl\n",
      "Number of invalid predictions: 10656\n",
      "Overall Start Points Prediction Accuracy: 0.8871445887994077\n",
      "Overall End Points Prediction Accuracy: 0.9093220087656113\n",
      "Data with predictions saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\labelled_trajectories_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the labelled dataset\n",
    "labelled_file = os.path.join(main_directory, 'labelled_trajectories.csv')\n",
    "labelled_df = pd.read_csv(labelled_file)\n",
    "\n",
    "# Define feature and target columns for start and end points\n",
    "feature_columns = ['User', 'Latitude(deg)', 'Longitude(deg)', 'Altitude(ft)', 'Date-Time']\n",
    "start_target = ['Start Latitude(deg)', 'Start Longitude(deg)', 'Start Time']\n",
    "end_target = ['End Latitude(deg)', 'End Longitude(deg)', 'End Time']\n",
    "\n",
    "# Ensure datetime columns are in the correct format\n",
    "labelled_df['Start Time'] = pd.to_datetime(labelled_df['Start Time'])\n",
    "labelled_df['End Time'] = pd.to_datetime(labelled_df['End Time'])\n",
    "labelled_df['Date-Time'] = pd.to_datetime(labelled_df['Date-Time'])\n",
    "\n",
    "# Convert datetime to numerical values (timestamp)\n",
    "labelled_df['Start Time'] = labelled_df['Start Time'].astype('int64') / 10**9\n",
    "labelled_df['End Time'] = labelled_df['End Time'].astype('int64') / 10**9\n",
    "labelled_df['Date-Time'] = labelled_df['Date-Time'].astype('int64') / 10**9\n",
    "\n",
    "# Features and targets for start points\n",
    "X_start = labelled_df[feature_columns]\n",
    "y_start = labelled_df[start_target]\n",
    "\n",
    "# Splitting the data for start points (80% training & 20% testing)\n",
    "X_start_train, X_start_test, y_start_train, y_start_test = train_test_split(X_start, y_start, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for start points\n",
    "start_param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [20],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "regressor_start = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search_start = GridSearchCV(estimator=regressor_start, param_grid=start_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_start.fit(X_start_train, y_start_train)\n",
    "best_start_regressor = grid_search_start.best_estimator_\n",
    "\n",
    "# Save the best start regressor model\n",
    "start_model_path = os.path.join(main_directory, 'start_points_regressor.pkl')\n",
    "joblib.dump(best_start_regressor, start_model_path)\n",
    "print(f\"Start points regressor model saved to {start_model_path}\")\n",
    "\n",
    "# Features and targets for end points\n",
    "X_end = labelled_df[feature_columns]\n",
    "y_end = labelled_df[end_target]\n",
    "\n",
    "# Splitting the data for end points (80% training & 20% testing)\n",
    "X_end_train, X_end_test, y_end_train, y_end_test = train_test_split(X_end, y_end, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for end points\n",
    "end_param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [20],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "regressor_end = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search_end = GridSearchCV(estimator=regressor_end, param_grid=end_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_end.fit(X_end_train, y_end_train)\n",
    "best_end_regressor = grid_search_end.best_estimator_\n",
    "\n",
    "# Save the best end regressor model\n",
    "end_model_path = os.path.join(main_directory, 'end_points_regressor.pkl')\n",
    "joblib.dump(best_end_regressor, end_model_path)\n",
    "print(f\"End points regressor model saved to {end_model_path}\")\n",
    "\n",
    "# Make predictions on the entire dataset for start and end points\n",
    "predicted_start_points = best_start_regressor.predict(X_start)\n",
    "predicted_end_points = best_end_regressor.predict(X_end)\n",
    "\n",
    "# Add predicted columns to dataframe\n",
    "labelled_df['Predicted Start Latitude(deg)'] = predicted_start_points[:, 0]\n",
    "labelled_df['Predicted Start Longitude(deg)'] = predicted_start_points[:, 1]\n",
    "labelled_df['Predicted Start Time'] = predicted_start_points[:, 2]\n",
    "labelled_df['Predicted End Latitude(deg)'] = predicted_end_points[:, 0]\n",
    "labelled_df['Predicted End Longitude(deg)'] = predicted_end_points[:, 1]\n",
    "labelled_df['Predicted End Time'] = predicted_end_points[:, 2]\n",
    "\n",
    "# Convert predicted start and end times back to datetime string format\n",
    "labelled_df['Predicted Start Time'] = pd.to_datetime(labelled_df['Predicted Start Time'], unit='s')\n",
    "labelled_df['Predicted End Time'] = pd.to_datetime(labelled_df['Predicted End Time'], unit='s')\n",
    "\n",
    "# Calculate distance, duration and speed for predicted points and ensure they are valid\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    from math import radians, cos, sin, sqrt, atan2\n",
    "    R = 6371  # Radius of the Earth in km\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "labelled_df['Predicted Distance(km)'] = labelled_df.apply(\n",
    "    lambda row: calculate_distance(row['Predicted Start Latitude(deg)'], row['Predicted Start Longitude(deg)'],\n",
    "                                   row['Predicted End Latitude(deg)'], row['Predicted End Longitude(deg)']), axis=1)\n",
    "\n",
    "labelled_df['Predicted Duration(hr)'] = (labelled_df['Predicted End Time'] - labelled_df['Predicted Start Time']).dt.total_seconds() / 3600\n",
    "labelled_df['Predicted Speed(km/h)'] = labelled_df['Predicted Distance(km)'] / labelled_df['Predicted Duration(hr)']\n",
    "\n",
    "# Filter out invalid distances and durations\n",
    "valid_predictions = (labelled_df['Predicted Distance(km)'] > 0) & (labelled_df['Predicted Duration(hr)'] > 0)\n",
    "invalid_predictions_count = (~valid_predictions).sum()\n",
    "print(f\"Number of invalid predictions: {invalid_predictions_count}\")\n",
    "\n",
    "# Evaluate accuracy by comparing predicted and original values\n",
    "labelled_df['Start Latitude Accurate'] = np.isclose(labelled_df['Start Latitude(deg)'], labelled_df['Predicted Start Latitude(deg)'], atol=0.0001)\n",
    "labelled_df['Start Longitude Accurate'] = np.isclose(labelled_df['Start Longitude(deg)'], labelled_df['Predicted Start Longitude(deg)'], atol=0.0001)\n",
    "labelled_df['Start Time Accurate'] = np.isclose(labelled_df['Start Time'], labelled_df['Predicted Start Time'].astype('int64') / 10**9, atol=60)  # Allow 1-minute difference\n",
    "labelled_df['End Latitude Accurate'] = np.isclose(labelled_df['End Latitude(deg)'], labelled_df['Predicted End Latitude(deg)'], atol=0.0001)\n",
    "labelled_df['End Longitude Accurate'] = np.isclose(labelled_df['End Longitude(deg)'], labelled_df['Predicted End Longitude(deg)'], atol=0.0001)\n",
    "labelled_df['End Time Accurate'] = np.isclose(labelled_df['End Time'], labelled_df['Predicted End Time'].astype('int64') / 10**9, atol=60)  # Allow 1-minute difference\n",
    "\n",
    "# Calculate overall accuracy for start and end points\n",
    "start_accuracy = labelled_df[['Start Latitude Accurate', 'Start Longitude Accurate', 'Start Time Accurate']].mean().mean()\n",
    "end_accuracy = labelled_df[['End Latitude Accurate', 'End Longitude Accurate', 'End Time Accurate']].mean().mean()\n",
    "\n",
    "print(f\"Overall Start Points Prediction Accuracy: {start_accuracy:}\")\n",
    "print(f\"Overall End Points Prediction Accuracy: {end_accuracy:}\")\n",
    "\n",
    "# Save labelled_df DataFrame to labelled_trajectories_with_predictions.csv\n",
    "output_file = os.path.join(main_directory, 'labelled_trajectories_with_predictions.csv')\n",
    "labelled_df.to_csv(output_file, index=False)\n",
    "print(f\"Data with predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeb2f0a-7080-42d8-9977-e7daa72cc7d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.2 Predict Start & End Points for Unlabelled Dataset to form Trajectories (use start_points_regressor.pkl & end_points_regressor.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93ead52-80e3-4c6e-a41e-204cbccbc283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid predictions: 1343723\n",
      "Predicted start and end points with metrics for unlabelled trajectories: \n",
      "          User                   Date-Time  Latitude(deg)  Longitude(deg)  \\\n",
      "0            0  2008-10-23 02:53:04.000000      39.984702      116.318417   \n",
      "1            0  2008-10-23 02:53:10.000000      39.984683      116.318450   \n",
      "2            0  2008-10-23 02:53:15.000000      39.984686      116.318417   \n",
      "3            0  2008-10-23 02:53:20.000000      39.984688      116.318385   \n",
      "4            0  2008-10-23 02:53:25.000000      39.984655      116.318263   \n",
      "...        ...                         ...            ...             ...   \n",
      "12359609   181  2008-03-14 03:39:56.000000      40.914867      111.710500   \n",
      "12359610   181  2008-03-14 03:41:17.000000      40.914267      111.710333   \n",
      "12359611   181  2008-03-14 03:43:02.000000      40.912467      111.710667   \n",
      "12359612   181  2008-03-14 03:43:28.000000      40.911517      111.711317   \n",
      "12359613   181  2008-03-14 03:43:40.000000      40.910933      111.711617   \n",
      "\n",
      "          Altitude(ft)  Predicted Start Latitude(deg)  \\\n",
      "0           492.000000                      39.975352   \n",
      "1           492.000000                      39.975352   \n",
      "2           492.000000                      39.975352   \n",
      "3           492.000000                      39.975352   \n",
      "4           492.000000                      39.975352   \n",
      "...                ...                            ...   \n",
      "12359609   3802.493438                      39.977733   \n",
      "12359610   3795.931759                      39.977733   \n",
      "12359611   3795.931759                      39.977733   \n",
      "12359612   3779.527559                      39.977733   \n",
      "12359613   3802.493438                      39.977733   \n",
      "\n",
      "          Predicted Start Longitude(deg)        Predicted Start Time  \\\n",
      "0                             116.324571  2008-10-23 02:02:52.000000   \n",
      "1                             116.324571  2008-10-23 02:02:52.000000   \n",
      "2                             116.324571  2008-10-23 02:02:52.000000   \n",
      "3                             116.324571  2008-10-23 02:02:52.000000   \n",
      "4                             116.324571  2008-10-23 02:02:52.000000   \n",
      "...                                  ...                         ...   \n",
      "12359609                      116.327500  2008-03-14 07:06:00.000000   \n",
      "12359610                      116.327500  2008-03-14 07:06:00.000000   \n",
      "12359611                      116.327500  2008-03-14 07:06:00.000000   \n",
      "12359612                      116.327500  2008-03-14 07:06:00.000000   \n",
      "12359613                      116.327500  2008-03-14 07:06:00.000000   \n",
      "\n",
      "          Predicted End Latitude(deg)  Predicted End Longitude(deg)  \\\n",
      "0                           39.964054                    116.329365   \n",
      "1                           39.964054                    116.329365   \n",
      "2                           39.964054                    116.329365   \n",
      "3                           39.964054                    116.329365   \n",
      "4                           39.964054                    116.329365   \n",
      "...                               ...                           ...   \n",
      "12359609                    40.001617                    116.324750   \n",
      "12359610                    40.001617                    116.324750   \n",
      "12359611                    40.001617                    116.324750   \n",
      "12359612                    40.001617                    116.324750   \n",
      "12359613                    40.001617                    116.324750   \n",
      "\n",
      "                  Predicted End Time  Predicted Distance(km)  \\\n",
      "0         2008-10-23 02:54:26.007985                1.320986   \n",
      "1         2008-10-23 02:54:26.007985                1.320986   \n",
      "2         2008-10-23 02:54:26.007985                1.320986   \n",
      "3         2008-10-23 02:54:26.007985                1.320986   \n",
      "4         2008-10-23 02:54:26.007985                1.320986   \n",
      "...                              ...                     ...   \n",
      "12359609  2008-03-14 07:17:56.000000                2.666019   \n",
      "12359610  2008-03-14 07:17:56.000000                2.666019   \n",
      "12359611  2008-03-14 07:17:56.000000                2.666019   \n",
      "12359612  2008-03-14 07:17:56.000000                2.666019   \n",
      "12359613  2008-03-14 07:17:56.000000                2.666019   \n",
      "\n",
      "          Predicted Duration(hr)  Predicted Speed(km/h)  \n",
      "0                       0.859447               1.537019  \n",
      "1                       0.859447               1.537019  \n",
      "2                       0.859447               1.537019  \n",
      "3                       0.859447               1.537019  \n",
      "4                       0.859447               1.537019  \n",
      "...                          ...                    ...  \n",
      "12359609                0.198889              13.404567  \n",
      "12359610                0.198889              13.404567  \n",
      "12359611                0.198889              13.404567  \n",
      "12359612                0.198889              13.404567  \n",
      "12359613                0.198889              13.404567  \n",
      "\n",
      "[11015891 rows x 14 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wengk.WK\\AppData\\Local\\Temp\\ipykernel_1296\\2920923400.py:111: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  trajectories = unlabelled_df.groupby(['User', 'Start Time', 'End Time'], group_keys=False).apply(create_trajectory).reset_index(name='Trajectory')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid predictions: 0\n",
      "Predicted trajectories: \n",
      "       User                                         Trajectory  Altitude(ft)  \\\n",
      "0         0  LINESTRING (116.31842 39.98470, 116.31845 39.9...    492.000000   \n",
      "1         0  LINESTRING (116.31432 39.98462, 116.31411 39.9...    113.000000   \n",
      "2         0  LINESTRING (116.32026 39.99128, 116.32045 39.9...     71.000000   \n",
      "3         0  LINESTRING (116.32215 39.99948, 116.32455 39.9...    148.000000   \n",
      "4         0  LINESTRING (116.32218 39.99961, 116.32232 39.9...    142.000000   \n",
      "...     ...                                                ...           ...   \n",
      "47301   181  LINESTRING (116.31097 39.98043, 116.31072 39.9...    167.322835   \n",
      "47302   181  LINESTRING (116.30895 39.98547, 116.30972 39.9...    223.097113   \n",
      "47303   181  LINESTRING (116.30000 39.98067, 116.29978 39.9...    754.593176   \n",
      "47304   181  LINESTRING (116.31235 39.97198, 116.31270 39.9...    216.535433   \n",
      "47305   181  LINESTRING (111.70922 40.91815, 111.70953 40.9...   3825.459318   \n",
      "\n",
      "                        Date-Time                  Start Time  \\\n",
      "0      2008-10-23 02:53:04.000000  2008-10-23 02:02:52.000000   \n",
      "1      2008-10-23 02:55:25.000000  2008-10-23 02:02:52.000000   \n",
      "2      2008-10-23 04:25:57.000000  2008-10-23 02:04:40.458170   \n",
      "3      2008-10-23 04:31:42.000000  2008-10-23 02:26:14.636412   \n",
      "4      2008-10-23 04:31:47.000000  2008-10-23 02:26:14.636412   \n",
      "...                           ...                         ...   \n",
      "47301  2008-02-16 08:40:19.000000  2008-02-29 21:51:08.799999   \n",
      "47302  2008-02-16 08:04:42.000000  2008-02-29 21:51:31.000000   \n",
      "47303  2008-02-16 08:59:27.000000  2008-02-29 21:51:31.000000   \n",
      "47304  2008-02-16 08:32:35.000000  2008-02-29 21:58:02.200000   \n",
      "47305  2008-03-14 02:57:55.000000  2008-03-14 07:06:00.000000   \n",
      "\n",
      "                         End Time  Start Longitude(deg)  Start Latitude(deg)  \\\n",
      "0      2008-10-23 02:54:26.007985            116.324571            39.975352   \n",
      "1      2008-10-23 03:02:07.728068            116.324571            39.975352   \n",
      "2      2008-10-23 03:02:07.728068            116.324613            39.976305   \n",
      "3      2008-10-23 02:56:27.068803            116.323764            39.990085   \n",
      "4      2008-10-23 02:56:18.340083            116.323764            39.990085   \n",
      "...                           ...                   ...                  ...   \n",
      "47301  2008-03-01 00:03:05.609999            116.330540            39.976168   \n",
      "47302  2008-03-01 00:03:38.009999            116.330586            39.976155   \n",
      "47303  2008-03-01 00:03:54.210000            116.330586            39.976155   \n",
      "47304  2008-03-01 00:07:08.609999            116.332189            39.975860   \n",
      "47305  2008-03-14 07:17:56.000000            116.327500            39.977733   \n",
      "\n",
      "       End Longitude(deg)  End Latitude(deg)  Distance(km)  Duration(hr)  \\\n",
      "0              116.329365          39.964054      1.320986      0.859447   \n",
      "1              116.334644          39.921905      6.004786      0.987702   \n",
      "2              116.334644          39.921905      6.109237      0.957575   \n",
      "3              116.330459          39.957024      3.720284      0.503453   \n",
      "4              116.330348          39.957979      3.613868      0.501029   \n",
      "...                   ...                ...           ...           ...   \n",
      "47301          116.330048          39.979510      0.373999      2.199114   \n",
      "47302          116.331040          39.979330      0.355224      2.201947   \n",
      "47303          116.331536          39.979240      0.352524      2.206447   \n",
      "47304          116.337488          39.978160      0.518937      2.151781   \n",
      "47305          116.324750          40.001617      2.666019      0.198889   \n",
      "\n",
      "       Speed(km/h)  \n",
      "0         1.537019  \n",
      "1         6.079551  \n",
      "2         6.379905  \n",
      "3         7.389529  \n",
      "4         7.212895  \n",
      "...            ...  \n",
      "47301     0.170068  \n",
      "47302     0.161323  \n",
      "47303     0.159770  \n",
      "47304     0.241166  \n",
      "47305    13.404567  \n",
      "\n",
      "[47306 rows x 13 columns]\n",
      "GeoDataFrame of Unlabelled Dataset saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\unlabelled_trajectories_geopandas.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine, Unit\n",
    "from shapely.geometry import LineString\n",
    "import geopandas as gpd\n",
    "import joblib\n",
    "\n",
    "# Load the trained regressor models for start and end points\n",
    "start_model_file = os.path.join(main_directory, 'start_points_regressor.pkl')\n",
    "end_model_file = os.path.join(main_directory, 'end_points_regressor.pkl')\n",
    "regressor_start = joblib.load(start_model_file)\n",
    "regressor_end = joblib.load(end_model_file)\n",
    "\n",
    "# Load the unlabelled dataset\n",
    "unlabelled_file = os.path.join(main_directory, 'unlabelled_trajectories.csv')\n",
    "unlabelled_df = pd.read_csv(unlabelled_file)\n",
    "\n",
    "# Ensure datetime columns are in the correct format\n",
    "unlabelled_df['Date-Time'] = pd.to_datetime(unlabelled_df['Date-Time'])\n",
    "unlabelled_df['Date-Time'] = unlabelled_df['Date-Time'].astype('int64') // 10**9\n",
    "\n",
    "# Extract features used in the trained models\n",
    "feature_columns = ['User', 'Latitude(deg)', 'Longitude(deg)', 'Altitude(ft)', 'Date-Time']\n",
    "\n",
    "# Ensure columns are in the same order as used during training\n",
    "unlabelled_features = unlabelled_df[feature_columns]\n",
    "\n",
    "# Predict start and end points for unlabelled data\n",
    "y_start_pred = regressor_start.predict(unlabelled_features)\n",
    "y_end_pred = regressor_end.predict(unlabelled_features)\n",
    "\n",
    "# Update 'Predicted' columns in unlabelled_df\n",
    "unlabelled_df['Predicted Start Latitude(deg)'] = y_start_pred[:, 0]\n",
    "unlabelled_df['Predicted Start Longitude(deg)'] = y_start_pred[:, 1]\n",
    "unlabelled_df['Predicted Start Time'] = y_start_pred[:, 2]\n",
    "\n",
    "unlabelled_df['Predicted End Latitude(deg)'] = y_end_pred[:, 0]\n",
    "unlabelled_df['Predicted End Longitude(deg)'] = y_end_pred[:, 1]\n",
    "unlabelled_df['Predicted End Time'] = y_end_pred[:, 2]\n",
    "\n",
    "# Ensure valid predictions for start and end times\n",
    "unlabelled_df['Predicted End Time'] = unlabelled_df.apply(\n",
    "    lambda row: max(row['Predicted End Time'], row['Predicted Start Time']), axis=1)\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    # Haversine formula to calculate distance between two points on the Earth\n",
    "    from math import radians, cos, sin, sqrt, atan2\n",
    "    R = 6371  # Radius of the Earth in km\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Calculate distance and duration for predicted points and ensure they are valid\n",
    "unlabelled_df['Predicted Distance(km)'] = unlabelled_df.apply(\n",
    "    lambda row: calculate_distance(row['Predicted Start Latitude(deg)'], row['Predicted Start Longitude(deg)'],\n",
    "                                   row['Predicted End Latitude(deg)'], row['Predicted End Longitude(deg)']), axis=1)\n",
    "\n",
    "unlabelled_df['Predicted Duration(hr)'] = (unlabelled_df['Predicted End Time'] - unlabelled_df['Predicted Start Time']) / 3600\n",
    "unlabelled_df['Predicted Speed(km/h)'] = unlabelled_df['Predicted Distance(km)'] / unlabelled_df['Predicted Duration(hr)']\n",
    "\n",
    "# Filter out invalid distances and durations\n",
    "valid_predictions = (unlabelled_df['Predicted Distance(km)'] > 0) & (unlabelled_df['Predicted Duration(hr)'] > 0)\n",
    "invalid_predictions_count = (~valid_predictions).sum()\n",
    "print(f\"Number of invalid predictions: {invalid_predictions_count}\")\n",
    "\n",
    "# Filter out invalid predictions\n",
    "unlabelled_df = unlabelled_df[valid_predictions]\n",
    "\n",
    "# Convert times back to datetime format\n",
    "unlabelled_df['Date-Time'] = pd.to_datetime(unlabelled_df['Date-Time'], unit='s')\n",
    "unlabelled_df['Predicted Start Time'] = pd.to_datetime(unlabelled_df['Predicted Start Time'], unit='s')\n",
    "unlabelled_df['Predicted End Time'] = pd.to_datetime(unlabelled_df['Predicted End Time'], unit='s')\n",
    "\n",
    "# Convert times to string format\n",
    "unlabelled_df['Date-Time'] = unlabelled_df['Date-Time'].dt.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "unlabelled_df['Predicted Start Time'] = unlabelled_df['Predicted Start Time'].dt.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "unlabelled_df['Predicted End Time'] = unlabelled_df['Predicted End Time'].dt.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "# Print unlabelled_df DataFrame\n",
    "print(f\"Predicted start and end points with metrics for unlabelled trajectories: \")\n",
    "print(unlabelled_df)\n",
    "\n",
    "# Combine Unlabelled Dataset to form Trajectories (No Transport Mode)\n",
    "# Rename columns to remove \"Predicted\" \n",
    "unlabelled_df.rename(columns={\n",
    "    'Predicted Start Time': 'Start Time',\n",
    "    'Predicted Start Longitude(deg)': 'Start Longitude(deg)',\n",
    "    'Predicted Start Latitude(deg)': 'Start Latitude(deg)',\n",
    "    'Predicted End Time': 'End Time',\n",
    "    'Predicted End Longitude(deg)': 'End Longitude(deg)',\n",
    "    'Predicted End Latitude(deg)': 'End Latitude(deg)',\n",
    "    'Predicted Distance(km)': 'Distance(km)',\n",
    "    'Predicted Duration(hr)': 'Duration(hr)',\n",
    "    'Predicted Speed(km/h)': 'Speed(km/h)'\n",
    "}, inplace=True)\n",
    "\n",
    "# Sort dataframe by User and Start Time\n",
    "unlabelled_df = unlabelled_df.sort_values(by=['User', 'Start Time'])\n",
    "\n",
    "# Function to create trajectories\n",
    "def create_trajectory(group):\n",
    "    if len(group) > 1:  # Ensure there are more than one point\n",
    "        return LineString(zip(group['Longitude(deg)'], group['Latitude(deg)']))\n",
    "    else:\n",
    "        return None  # Return None if there's only one point\n",
    "\n",
    "# Group by User, Start Time, and End Time and create trajectories\n",
    "trajectories = unlabelled_df.groupby(['User', 'Start Time', 'End Time'], group_keys=False).apply(create_trajectory).reset_index(name='Trajectory')\n",
    "\n",
    "# Filter out None trajectories\n",
    "trajectories = trajectories[trajectories['Trajectory'].notnull()]\n",
    "\n",
    "# Merge trajectories back to the original dataframe, keeping only the first occurrence of each combination of User, Start Time, and End Time\n",
    "unlabelled_df = unlabelled_df.drop(columns=['Longitude(deg)', 'Latitude(deg)'])\n",
    "unlabelled_df = pd.merge(unlabelled_df.drop_duplicates(subset=['User', 'Start Time', 'End Time']), trajectories, on=['User', 'Start Time', 'End Time'])\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(unlabelled_df, geometry='Trajectory')\n",
    "\n",
    "# Filter out invalid values for Distance or Duration or Speed\n",
    "valid_predictions = (gdf['Distance(km)'] > 0) & (gdf['Duration(hr)'] > 0) & (gdf['Speed(km/h)'] > 0)\n",
    "invalid_predictions_count = (~valid_predictions).sum()\n",
    "print(f\"Number of invalid predictions: {invalid_predictions_count}\")\n",
    "\n",
    "# View the trajectories with additional columns\n",
    "print(f\"Predicted trajectories: \")\n",
    "print(gdf[['User', 'Trajectory', 'Altitude(ft)', 'Date-Time', 'Start Time', 'End Time', 'Start Longitude(deg)', \n",
    "           'Start Latitude(deg)', 'End Longitude(deg)', 'End Latitude(deg)', 'Distance(km)', 'Duration(hr)', 'Speed(km/h)']])\n",
    "\n",
    "# Save the GeoDataFrame to unlabelled_trajectories_geopandas.csv file\n",
    "output_file_path = os.path.join(main_directory, 'unlabelled_trajectories_geopandas.csv')\n",
    "gdf.to_csv(output_file_path, index=False)\n",
    "print(f\"GeoDataFrame of Unlabelled Dataset saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101acc0-6dcd-4230-9484-e3438e47d7a6",
   "metadata": {},
   "source": [
    "# 3. Model to Predict Transport Mode "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec384f90-f5cf-4d35-b8db-8117c01b577a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.1 Train & Evaluate Model using labelled data - XGBoost Classifier (99%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80043b2e-decb-4be2-ae3c-fac7ece0d6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy: 0.9997909698996655\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bike       1.00      1.00      1.00      1572\n",
      "         Bus       1.00      1.00      1.00      1866\n",
      "         Car       1.00      1.00      1.00      1307\n",
      "       Train       1.00      1.00      1.00       787\n",
      "        Walk       1.00      1.00      1.00      4036\n",
      "\n",
      "    accuracy                           1.00      9568\n",
      "   macro avg       1.00      1.00      1.00      9568\n",
      "weighted avg       1.00      1.00      1.00      9568\n",
      "\n",
      "Trained model saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\transport_mode_classifier.pkl\n",
      "Label encoder saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\label_encoder.pkl\n",
      "Labelled trajectories with predictions saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\labelled_trajectories_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the feature columns and target column\n",
    "feature_columns = ['Altitude(ft)', 'Start Time', 'End Time', 'Start Longitude(deg)', 'Start Latitude(deg)', \n",
    "                   'End Longitude(deg)', 'End Latitude(deg)', 'Distance(km)', 'Duration(hr)', 'Speed(km/h)']\n",
    "\n",
    "# Load the labelled data\n",
    "labelled_file = os.path.join(main_directory, 'labelled_trajectories_geopandas.csv')\n",
    "labelled_df = pd.read_csv(labelled_file)\n",
    "\n",
    "# Ensure datetime columns are in the correct format\n",
    "labelled_df['Start Time'] = pd.to_datetime(labelled_df['Start Time'])\n",
    "labelled_df['End Time'] = pd.to_datetime(labelled_df['End Time'])\n",
    "\n",
    "# Convert datetime to numerical values (timestamp)\n",
    "labelled_df['Start Time'] = labelled_df['Start Time'].astype('int64') // 10**9\n",
    "labelled_df['End Time'] = labelled_df['End Time'].astype('int64') // 10**9\n",
    "\n",
    "# Reset index of the DataFrame\n",
    "labelled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Features and target\n",
    "X = labelled_df[feature_columns]\n",
    "y = labelled_df['Transportation Mode']\n",
    "\n",
    "# Encode the target variable as numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_), random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [0.15],\n",
    "    'subsample': [0.85],\n",
    "    'colsample_bytree': [0.55],\n",
    "    'reg_alpha': [0.05],\n",
    "    'reg_lambda': [2.0],\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X, y_encoded)\n",
    "\n",
    "# Get the best model from the search\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y_pred_encoded = best_xgb_model.predict(X)\n",
    "\n",
    "# Decode the predicted and true labels back to original transportation modes\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Evaluate the predictions\n",
    "accuracy = accuracy_score(y, y_pred_decoded)\n",
    "report = classification_report(y, y_pred_decoded)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "# Save the best model to a file\n",
    "model_file = os.path.join(main_directory, 'transport_mode_classifier.pkl')\n",
    "joblib.dump(best_xgb_model, model_file)\n",
    "print(f\"Trained model saved to {model_file}\")\n",
    "\n",
    "# Add 'Predicted Transport Mode' column\n",
    "labelled_df['Predicted Transport Mode'] = y_pred_decoded\n",
    "\n",
    "# Convert numeric times back to date-time format\n",
    "labelled_df['Start Time'] = pd.to_datetime(labelled_df['Start Time'], unit='s')\n",
    "labelled_df['End Time'] = pd.to_datetime(labelled_df['End Time'], unit='s')\n",
    "\n",
    "# Convert datetime columns to the desired string format\n",
    "labelled_df['Start Time'] = labelled_df['Start Time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "labelled_df['End Time'] = labelled_df['End Time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Save the label encoder to a file\n",
    "encoder_file = os.path.join(main_directory, 'label_encoder.pkl')\n",
    "joblib.dump(label_encoder, encoder_file)\n",
    "print(f\"Label encoder saved to {encoder_file}\")\n",
    "\n",
    "# Save the updated dataframe with predictions to a new CSV file\n",
    "output_file_with_predictions = os.path.join(main_directory, 'labelled_trajectories_with_predictions.csv')\n",
    "labelled_df.to_csv(output_file_with_predictions, index=False)\n",
    "print(f\"Labelled trajectories with predictions saved to {output_file_with_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6725e5-1388-492a-a447-f7cfe667058b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest_set\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_set' is not defined"
     ]
    }
   ],
   "source": [
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c5829-eadf-4ee7-b945-ee566ccf2f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(labelled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e88636a-248a-46e9-8121-5c3360b951f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2 Predict Mode of Transport for Unlabelled Data (use XGBoost transport_mode_classifier.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44fc302f-c97a-43a3-bfed-53474087e56d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with NaN in Start or End Time columns: 0\n",
      "       User            Date-Time  Altitude(ft)  Start Latitude(deg)  \\\n",
      "0         0  2008-10-23 02:53:04    492.000000            39.975352   \n",
      "1         0  2008-10-23 02:55:25    113.000000            39.975352   \n",
      "2         0  2008-10-23 04:25:57     71.000000            39.976305   \n",
      "3         0  2008-10-23 04:31:42    148.000000            39.990085   \n",
      "4         0  2008-10-23 04:31:47    142.000000            39.990085   \n",
      "...     ...                  ...           ...                  ...   \n",
      "47301   181  2008-02-16 08:40:19    167.322835            39.976168   \n",
      "47302   181  2008-02-16 08:04:42    223.097113            39.976155   \n",
      "47303   181  2008-02-16 08:59:27    754.593176            39.976155   \n",
      "47304   181  2008-02-16 08:32:35    216.535433            39.975860   \n",
      "47305   181  2008-03-14 02:57:55   3825.459318            39.977733   \n",
      "\n",
      "       Start Longitude(deg)                    Start Time  End Latitude(deg)  \\\n",
      "0                116.324571 2008-10-23 02:02:52.000000000          39.964054   \n",
      "1                116.324571 2008-10-23 02:02:52.000000000          39.921905   \n",
      "2                116.324613 2008-10-23 02:04:40.458170112          39.921905   \n",
      "3                116.323764 2008-10-23 02:26:14.636411904          39.957024   \n",
      "4                116.323764 2008-10-23 02:26:14.636411904          39.957979   \n",
      "...                     ...                           ...                ...   \n",
      "47301            116.330540 2008-02-29 21:51:08.799998976          39.979510   \n",
      "47302            116.330586 2008-02-29 21:51:31.000000000          39.979330   \n",
      "47303            116.330586 2008-02-29 21:51:31.000000000          39.979240   \n",
      "47304            116.332189 2008-02-29 21:58:02.200000000          39.978160   \n",
      "47305            116.327500 2008-03-14 07:06:00.000000000          40.001617   \n",
      "\n",
      "       End Longitude(deg)                      End Time  Distance(km)  \\\n",
      "0              116.329365 2008-10-23 02:54:26.007984128      1.320986   \n",
      "1              116.334644 2008-10-23 03:02:07.728068096      6.004786   \n",
      "2              116.334644 2008-10-23 03:02:07.728068096      6.109237   \n",
      "3              116.330459 2008-10-23 02:56:27.068803072      3.720284   \n",
      "4              116.330348 2008-10-23 02:56:18.340082944      3.613868   \n",
      "...                   ...                           ...           ...   \n",
      "47301          116.330048 2008-03-01 00:03:05.609999104      0.373999   \n",
      "47302          116.331040 2008-03-01 00:03:38.009999104      0.355224   \n",
      "47303          116.331536 2008-03-01 00:03:54.209999872      0.352524   \n",
      "47304          116.337488 2008-03-01 00:07:08.609999104      0.518937   \n",
      "47305          116.324750 2008-03-14 07:17:56.000000000      2.666019   \n",
      "\n",
      "       Duration(hr)  Speed(km/h)  \\\n",
      "0          0.859447     1.537019   \n",
      "1          0.987702     6.079551   \n",
      "2          0.957575     6.379905   \n",
      "3          0.503453     7.389529   \n",
      "4          0.501029     7.212895   \n",
      "...             ...          ...   \n",
      "47301      2.199114     0.170068   \n",
      "47302      2.201947     0.161323   \n",
      "47303      2.206447     0.159770   \n",
      "47304      2.151781     0.241166   \n",
      "47305      0.198889    13.404567   \n",
      "\n",
      "                                              Trajectory  \\\n",
      "0      LINESTRING (116.318417 39.984702, 116.31845 39...   \n",
      "1      LINESTRING (116.314323 39.984618, 116.314107 3...   \n",
      "2      LINESTRING (116.320255 39.991282, 116.320445 3...   \n",
      "3      LINESTRING (116.322148 39.999484, 116.324545 3...   \n",
      "4      LINESTRING (116.322178 39.999607, 116.322324 3...   \n",
      "...                                                  ...   \n",
      "47301  LINESTRING (116.310966666667 39.9804333333333,...   \n",
      "47302  LINESTRING (116.30895 39.9854666666667, 116.30...   \n",
      "47303  LINESTRING (116.3 39.9806666666667, 116.299783...   \n",
      "47304  LINESTRING (116.31235 39.9719833333333, 116.31...   \n",
      "47305  LINESTRING (111.709216666667 40.91815, 111.709...   \n",
      "\n",
      "      Predicted Transportation Mode  \n",
      "0                              Walk  \n",
      "1                              Walk  \n",
      "2                               Bus  \n",
      "3                              Bike  \n",
      "4                              Bike  \n",
      "...                             ...  \n",
      "47301                          Walk  \n",
      "47302                          Walk  \n",
      "47303                          Walk  \n",
      "47304                          Walk  \n",
      "47305                          Bike  \n",
      "\n",
      "[47306 rows x 14 columns]\n",
      "Predicted transport modes for unlabelled trajectories saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\predicted_trajectories_transport.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model_file = os.path.join(main_directory, 'transport_mode_classifier.pkl')\n",
    "clf = joblib.load(model_file)\n",
    "\n",
    "# Load the unlabelled trajectories dataset\n",
    "unlabelled_file = os.path.join(main_directory, 'unlabelled_trajectories_geopandas.csv')\n",
    "unlabelled_df = pd.read_csv(unlabelled_file)\n",
    "\n",
    "# Load the label encoder from a file\n",
    "encoder_file = os.path.join(main_directory, 'label_encoder.pkl')\n",
    "label_encoder = joblib.load(encoder_file)\n",
    "\n",
    "# Ensure datetime columns are in the correct format\n",
    "unlabelled_df['Start Time'] = pd.to_datetime(unlabelled_df['Start Time'], errors='coerce')\n",
    "unlabelled_df['End Time'] = pd.to_datetime(unlabelled_df['End Time'], errors='coerce')\n",
    "\n",
    "# Check if any NaN values in 'Start Time' or 'End Time' column\n",
    "nan_start = unlabelled_df['Start Time'].isna().sum()\n",
    "nan_end = unlabelled_df['End Time'].isna().sum()\n",
    "nan_time = nan_start + nan_end\n",
    "print(f\"Number of records with NaN in Start or End Time columns: {nan_time}\")\n",
    "\n",
    "# Drop rows with NaT values in 'Start Time' or 'End Time'\n",
    "unlabelled_df.dropna(subset=['Start Time', 'End Time'], inplace=True)\n",
    "\n",
    "# Convert datetime to numerical values (timestamp)\n",
    "unlabelled_df['Start Time'] = unlabelled_df['Start Time'].astype('int64') / 10**9\n",
    "unlabelled_df['End Time'] = unlabelled_df['End Time'].astype('int64') / 10**9\n",
    "\n",
    "# Extract features used in the trained model\n",
    "feature_columns = ['Altitude(ft)', 'Start Time', 'End Time', 'Start Longitude(deg)', 'Start Latitude(deg)', \n",
    "                   'End Longitude(deg)', 'End Latitude(deg)', 'Distance(km)', 'Duration(hr)', 'Speed(km/h)']\n",
    "\n",
    "# Ensure columns are in the same order as used during training\n",
    "unlabelled_features = unlabelled_df[feature_columns]\n",
    "\n",
    "# Check for and handle large or infinite values in 'Speed'\n",
    "max_speed = unlabelled_features[unlabelled_features['Speed(km/h)'] != np.inf]['Speed(km/h)'].max()\n",
    "unlabelled_features.loc[unlabelled_features['Speed(km/h)'] == np.inf, 'Speed(km/h)'] = max_speed\n",
    "\n",
    "# Predict transport modes for unlabelled data\n",
    "predicted_modes = clf.predict(unlabelled_features)\n",
    "\n",
    "# Decode the predicted modes from numerical labels to original mode names\n",
    "predicted_modes_decoded = label_encoder.inverse_transform(predicted_modes)\n",
    "\n",
    "# Update 'Predicted Transport Mode' column in unlabelled_df\n",
    "unlabelled_df['Predicted Transportation Mode'] = predicted_modes_decoded\n",
    "\n",
    "# Convert numerical times back to datetime format\n",
    "unlabelled_df['Start Time'] = pd.to_datetime(unlabelled_df['Start Time'] * 10**9)\n",
    "unlabelled_df['End Time'] = pd.to_datetime(unlabelled_df['End Time'] * 10**9)\n",
    "\n",
    "# Print unlabelled_df DataFrame\n",
    "print(unlabelled_df)\n",
    "\n",
    "# Save unlabelled_df dataframe to predicted_trajectories_transport.csv file\n",
    "output_file_path = os.path.join(main_directory, 'predicted_trajectories_transport.csv')\n",
    "unlabelled_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Predicted transport modes for unlabelled trajectories saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87bb70bc-cb62-479f-bdc4-a5ecf67907c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of records for each transportation mode:\n",
      "Predicted Transportation Mode\n",
      "Walk     26900\n",
      "Bus      10820\n",
      "Car       4084\n",
      "Train     3841\n",
      "Bike      1661\n",
      "Name: count, dtype: int64\n",
      "Number of records with NaN in Transport Mode column: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Count of records for each unique transportation mode\n",
    "mode_counts = unlabelled_df['Predicted Transportation Mode'].value_counts()\n",
    "print(\"Counts of records for each transportation mode:\")\n",
    "print(mode_counts)\n",
    "\n",
    "# Check if any NaN values in Transportation Mode column\n",
    "nan_count = unlabelled_df['Predicted Transportation Mode'].isna().sum()\n",
    "print(f\"Number of records with NaN in Transport Mode column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681e2fa-fedd-4658-bf66-ff50968b2cb2",
   "metadata": {},
   "source": [
    "# 4. Form Combined Trajectories Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588a326-17f9-43ab-a8ce-7ab0f0bf0809",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1 Combine Labelled & Predicted Unlabelled Trajectories (combined_trajectories_predictions.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e418c5e9-97c4-47b9-b07a-c0d75ea122eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       User Transportation Mode            Date-Time  Altitude(ft)  \\\n",
      "0        10               Train  2008-03-28 14:54:40   -777.000000   \n",
      "1        10               Train  2008-03-28 16:00:01   -777.000000   \n",
      "2        10               Train  2008-03-29 01:32:52   -777.000000   \n",
      "3        10               Train  2008-03-29 16:00:48   -777.000000   \n",
      "4        10               Train  2008-03-30 16:00:39   -777.000000   \n",
      "...     ...                 ...                  ...           ...   \n",
      "56869   181                Walk  2008-02-16 08:40:19    167.322835   \n",
      "56870   181                Walk  2008-02-16 08:04:42    223.097113   \n",
      "56871   181                Walk  2008-02-16 08:59:27    754.593176   \n",
      "56872   181                Walk  2008-02-16 08:32:35    216.535433   \n",
      "56873   181                Bike  2008-03-14 02:57:55   3825.459318   \n",
      "\n",
      "                Start Time             End Time  Start Latitude(deg)  \\\n",
      "0      2008-03-28 14:52:54  2008-03-28 15:59:59            39.894178   \n",
      "1      2008-03-28 16:00:00  2008-03-28 22:02:00            39.502930   \n",
      "2      2008-03-29 01:27:50  2008-03-29 15:59:59            36.663282   \n",
      "3      2008-03-29 16:00:00  2008-03-30 15:59:59            34.497127   \n",
      "4      2008-03-30 16:00:00  2008-03-31 03:13:11            41.147205   \n",
      "...                    ...                  ...                  ...   \n",
      "56869  2008-02-29 21:51:08  2008-03-01 00:03:05            39.976168   \n",
      "56870  2008-02-29 21:51:31  2008-03-01 00:03:38            39.976155   \n",
      "56871  2008-02-29 21:51:31  2008-03-01 00:03:54            39.976155   \n",
      "56872  2008-02-29 21:58:02  2008-03-01 00:07:08            39.975860   \n",
      "56873  2008-03-14 07:06:00  2008-03-14 07:17:56            39.977733   \n",
      "\n",
      "       Start Longitude(deg)  End Latitude(deg)  End Longitude(deg)  \\\n",
      "0                116.318200          39.506952          116.707353   \n",
      "1                116.714948          36.671463          116.988268   \n",
      "2                116.959467          34.490502          109.629697   \n",
      "3                109.619872          41.137635           95.465557   \n",
      "4                 95.457762          43.697033           87.576190   \n",
      "...                     ...                ...                 ...   \n",
      "56869            116.330540          39.979510          116.330048   \n",
      "56870            116.330586          39.979330          116.331040   \n",
      "56871            116.330586          39.979240          116.331536   \n",
      "56872            116.332189          39.978160          116.337488   \n",
      "56873            116.327500          40.001617          116.324750   \n",
      "\n",
      "                                              Trajectory  Distance(km)  \\\n",
      "0      LINESTRING (116.3182 39.894178, 116.321132 39....     62.604343   \n",
      "1      LINESTRING (116.714948 39.50293, 116.726137 39...    409.116643   \n",
      "2      LINESTRING (116.959467 36.663282, 116.956267 3...   1071.454161   \n",
      "3      LINESTRING (109.619872 34.497127, 109.6054 34....   1588.784518   \n",
      "4      LINESTRING (95.457762 41.147205, 95.444897 41....    772.508295   \n",
      "...                                                  ...           ...   \n",
      "56869  LINESTRING (116.310966666667 39.9804333333333,...      0.373999   \n",
      "56870  LINESTRING (116.30895 39.9854666666667, 116.30...      0.355224   \n",
      "56871  LINESTRING (116.3 39.9806666666667, 116.299783...      0.352524   \n",
      "56872  LINESTRING (116.31235 39.9719833333333, 116.31...      0.518937   \n",
      "56873  LINESTRING (111.709216666667 40.91815, 111.709...      2.666019   \n",
      "\n",
      "       Duration(hr)  Speed(km/h)  \n",
      "0          1.118056    55.993947  \n",
      "1          6.033333    67.809388  \n",
      "2         14.535833    73.711230  \n",
      "3         23.999722    66.200121  \n",
      "4         11.219722    68.852711  \n",
      "...             ...          ...  \n",
      "56869      2.199114     0.170068  \n",
      "56870      2.201947     0.161323  \n",
      "56871      2.206447     0.159770  \n",
      "56872      2.151781     0.241166  \n",
      "56873      0.198889    13.404567  \n",
      "\n",
      "[56874 rows x 14 columns]\n",
      "Combined dataset with predictions saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\combined_trajectories_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load labelled dataset\n",
    "labelled_file = os.path.join(main_directory, 'labelled_trajectories_geopandas.csv')\n",
    "labelled_df = pd.read_csv(labelled_file, parse_dates=['Start Time', 'End Time'])\n",
    "\n",
    "# Load predicted unlabelled dataset\n",
    "unlabelled_file = os.path.join(main_directory, 'predicted_trajectories_transport.csv')\n",
    "unlabelled_predicted_df = pd.read_csv(unlabelled_file, parse_dates=['Start Time', 'End Time'])\n",
    "\n",
    "# Rename Predicted Transportation Mode column to Transportation Mode in unlabelled_predicted_df\n",
    "unlabelled_predicted_df.rename(columns={'Predicted Transportation Mode': 'Transportation Mode'}, inplace=True)\n",
    "\n",
    "# Combine the labelled and unlabelled datasets\n",
    "combined_df = pd.concat([labelled_df, unlabelled_predicted_df], ignore_index=True)\n",
    "\n",
    "# Ensure Date-Time columns are in datetime format\n",
    "datetime_columns = ['Date-Time', 'Start Time', 'End Time']\n",
    "for column in datetime_columns:\n",
    "    if column in combined_df.columns:\n",
    "        combined_df[column] = pd.to_datetime(combined_df[column], errors='coerce')\n",
    "\n",
    "# Convert datetime columns to YYYY-MM-DD HH:MM:SS format\n",
    "for column in datetime_columns:\n",
    "    if column in combined_df.columns:\n",
    "        combined_df[column] = combined_df[column].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Print combined_df DataFrame\n",
    "print(combined_df)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "output_combined_file = os.path.join(main_directory, 'combined_trajectories_predictions.csv')\n",
    "combined_df.to_csv(output_combined_file, index=False)\n",
    "print(f\"Combined dataset with predictions saved to {output_combined_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e64fea2-fc23-4965-8b04-37e72eaff7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of records for each transportation mode:\n",
      "Transportation Mode\n",
      "Walk     30936\n",
      "Bus      12686\n",
      "Car       5391\n",
      "Train     4628\n",
      "Bike      3233\n",
      "Name: count, dtype: int64\n",
      "Number of records with NaN in Transport Mode column: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Count of records for each unique transportation mode\n",
    "mode_counts = combined_df['Transportation Mode'].value_counts()\n",
    "print(\"Counts of records for each transportation mode:\")\n",
    "print(mode_counts)\n",
    "\n",
    "# Check if any NaN values in Transportation Mode column\n",
    "nan_count = combined_df['Transportation Mode'].isna().sum()\n",
    "print(f\"Number of records with NaN in Transport Mode column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f421b46-1907-4446-95a1-a57319eb5ad7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2. Generate Anomalous Trajectories (5% of combined dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d24e31-71fa-4e27-af69-2eef48507724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Manim\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\tools\\Manim\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       User Transportation Mode           Date-Time  Altitude(ft)  \\\n",
      "2        10               Train 2008-03-29 01:32:52   -777.000000   \n",
      "13       10                Walk 2008-04-01 11:30:37   -777.000000   \n",
      "126      10                 Bus 2008-09-17 22:56:54      7.000000   \n",
      "132      10                Walk 2008-09-18 00:53:08    167.000000   \n",
      "145      10                Walk 2008-09-19 11:00:03    161.000000   \n",
      "...     ...                 ...                 ...           ...   \n",
      "56809   172                 Car 2008-06-28 05:03:23     95.100000   \n",
      "56818   172                Walk 2008-07-18 11:14:30     98.400000   \n",
      "56820   172                Walk 2008-07-18 11:14:40     98.400000   \n",
      "56831   176                Bike 2007-11-30 09:33:10    272.309711   \n",
      "56861   181                Walk 2007-12-07 10:06:05    226.377953   \n",
      "\n",
      "                Start Time             End Time  Start Latitude(deg)  \\\n",
      "2      2008-03-29 01:27:50  2008-03-29 15:59:59            36.663282   \n",
      "13     2008-04-01 11:30:37  2008-04-01 11:35:35            39.475128   \n",
      "126    2008-09-17 22:56:54  2008-09-17 23:01:52            39.137186   \n",
      "132    2008-09-18 00:53:08  2008-09-18 00:57:08            39.991356   \n",
      "145    2008-09-19 11:00:03  2008-09-19 11:01:25            39.939388   \n",
      "...                    ...                  ...                  ...   \n",
      "56809  2008-06-28 04:39:37  2008-06-28 12:22:03            39.021020   \n",
      "56818  2008-07-18 10:16:30  2008-07-18 10:24:50            39.976136   \n",
      "56820  2008-07-18 10:21:32  2008-07-18 10:24:50            39.975943   \n",
      "56831  2007-11-29 02:02:53  2007-11-29 14:21:00            39.966713   \n",
      "56861  2007-11-29 22:19:39  2007-11-30 06:34:04            39.952737   \n",
      "\n",
      "       Start Longitude(deg)  End Latitude(deg)  End Longitude(deg)  \\\n",
      "2                116.959467          34.490502          109.629697   \n",
      "13                75.999173          39.473507           76.000835   \n",
      "126              117.213814          39.138576          117.200268   \n",
      "132              116.331358          39.991246          116.327628   \n",
      "145              116.347235          39.939545          116.348161   \n",
      "...                     ...                ...                 ...   \n",
      "56809            116.462773          39.973525          116.330967   \n",
      "56818            116.331999          39.975914          116.330915   \n",
      "56820            116.332456          39.975914          116.330915   \n",
      "56831            116.344933          39.976255          116.330807   \n",
      "56861            116.389118          39.953342          116.342175   \n",
      "\n",
      "                                              Trajectory  Distance(km)  \\\n",
      "2      LINESTRING (116.959467 36.663282, 116.956267 3...   1071.454161   \n",
      "13     LINESTRING (75.999173 39.475128, 75.9991 39.47...      0.273843   \n",
      "126    LINESTRING (117.213814 39.137186, 117.213794 3...      1.908602   \n",
      "132    LINESTRING (116.331358 39.991356, 116.331333 3...      0.414367   \n",
      "145    LINESTRING (116.347235 39.939388, 116.347275 3...      0.418174   \n",
      "...                                                  ...           ...   \n",
      "56809  LINESTRING (-149.0629233 60.8465016, -149.0621...     83.448942   \n",
      "56818  LINESTRING (116.3312366 39.9881233, 116.331213...      0.612515   \n",
      "56820  LINESTRING (116.331305 39.9880783, 116.3313149...      0.419669   \n",
      "56831  LINESTRING (116.330216666667 39.9762, 116.3303...      4.685983   \n",
      "56861  LINESTRING (116.330266666667 39.9761, 116.331 ...     39.180458   \n",
      "\n",
      "       Duration(hr)  Speed(km/h)  Anomalous  \n",
      "2         14.535833    73.711230          1  \n",
      "13         0.082778     3.308170          1  \n",
      "126        0.082778    23.056934          1  \n",
      "132        0.066667     6.215509          1  \n",
      "145        0.022778    18.358865          1  \n",
      "...             ...          ...        ...  \n",
      "56809      7.707222    10.827369          1  \n",
      "56818      0.138889     4.410105          1  \n",
      "56820      0.055000     7.630342          1  \n",
      "56831     12.301944     0.380914          1  \n",
      "56861      8.240278     4.754750          1  \n",
      "\n",
      "[2843 rows x 15 columns]\n",
      "Anomalous trajectories saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\generated_anomalous_trajectories.csv\n",
      "Total number of anomalous trajectories generated: 2843\n",
      "\n",
      "Count of anomalous trajectories generated for each mode of transport:\n",
      "Transportation Mode\n",
      "Walk     1587\n",
      "Bus       595\n",
      "Car       260\n",
      "Train     239\n",
      "Bike      162\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString\n",
    "import random\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, atan2, sqrt\n",
    "\n",
    "# Load combined_trajectories_predictions.csv\n",
    "file_path = os.path.join(main_directory, 'combined_trajectories_predictions.csv')\n",
    "df = pd.read_csv(file_path, parse_dates=['Date-Time'])\n",
    "\n",
    "# Function to parse each trajectory individually\n",
    "def parse_trajectories(trajectory_string):\n",
    "    # Remove 'LINESTRING (' and ')'\n",
    "    coords_str = trajectory_string.replace('LINESTRING (', '').replace(')', '')\n",
    "        \n",
    "    # Split by ', ' to get individual coordinate pairs\n",
    "    coord_pairs = coords_str.split(', ')\n",
    "        \n",
    "    # Ensure there are at least two coordinates for a LineString\n",
    "    if len(coord_pairs) < 2:\n",
    "        raise ValueError(f\"Insufficient coordinate pairs in LineString representation: {trajectory_string}\")\n",
    "        \n",
    "    # Extract coordinates\n",
    "    coords = []\n",
    "    for coord_pair in coord_pairs:\n",
    "        lon_lat = coord_pair.split()  # Split by space to get longitude and latitude\n",
    "        if len(lon_lat) != 2:\n",
    "            raise ValueError(f\"Invalid coordinate pair format: {coord_pair}\")\n",
    "        lon = float(lon_lat[0])\n",
    "        lat = float(lon_lat[1])\n",
    "        coords.append((lon, lat))\n",
    "        \n",
    "    return LineString(coords)\n",
    "\n",
    "# Convert 'Trajectory' column to LineString objects\n",
    "df['Parsed_Trajectory'] = df['Trajectory'].apply(parse_trajectories)\n",
    "\n",
    "# Drop rows where Parsed_Trajectory is None\n",
    "df = df.dropna(subset=['Parsed_Trajectory'])\n",
    "\n",
    "# Determine the number of trajectories to modify (5% of total)\n",
    "anomalous_count = int(len(df) * 0.05) \n",
    "\n",
    "# Select random indices of trajectories to modify\n",
    "anomalous_indices = random.sample(df.index.tolist(), anomalous_count)\n",
    "\n",
    "# Function to calculate Anomaly Correlation Coefficient (ACC)\n",
    "def calculate_acc(original_coords, modified_coords):\n",
    "    original_array = np.array(original_coords)\n",
    "    modified_array = np.array(modified_coords)\n",
    "    \n",
    "    # Compute correlation coefficient between original and modified trajectories\n",
    "    acc = np.corrcoef(original_array[:, 0], modified_array[:, 0])[0, 1] * np.corrcoef(original_array[:, 1], modified_array[:, 1])[0, 1]\n",
    "    return acc\n",
    "\n",
    "# Function to generate anomalous trajectories based on ACC formula\n",
    "def generate_anomalous_trajectory(original_trajectory, threshold=0.5):\n",
    "    # Convert LineString to list of coordinates\n",
    "    coordinates = list(original_trajectory.coords)\n",
    "        \n",
    "    # Number of deviations (5 to 10)\n",
    "    num_deviations = random.randint(5, 10)\n",
    "        \n",
    "    # Generate random indices to insert deviations\n",
    "    positions = random.sample(range(1, len(coordinates)), min(num_deviations, len(coordinates) - 1))\n",
    "        \n",
    "    # Apply deviations until the ACC drops below the threshold\n",
    "    for pos in sorted(positions, reverse=True):\n",
    "        deviation = (coordinates[pos][0] + random.uniform(-0.001, 0.001), \n",
    "                        coordinates[pos][1] + random.uniform(-0.001, 0.001))  \n",
    "        modified_coords = coordinates[:pos] + [deviation] + coordinates[pos+1:]\n",
    "            \n",
    "        # Calculate ACC\n",
    "        acc = calculate_acc(coordinates, modified_coords)\n",
    "        if acc < threshold:\n",
    "            coordinates = modified_coords\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return LineString(coordinates)\n",
    "\n",
    "# Define Haversine formula\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of the Earth in km\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Calculate Distance using Haversine formula\n",
    "def calculate_trajectory_distance(trajectory):\n",
    "    if isinstance(trajectory, LineString):\n",
    "        coords = list(trajectory.coords)\n",
    "        distance = 0\n",
    "        for i in range(len(coords) - 1):\n",
    "            lon1, lat1 = coords[i]\n",
    "            lon2, lat2 = coords[i + 1]\n",
    "            distance += calculate_distance(lat1, lon1, lat2, lon2)\n",
    "        return distance\n",
    "    return 0\n",
    "\n",
    "# Apply anomaly generation to selected trajectories\n",
    "df.loc[df.index.isin(anomalous_indices), 'Parsed_Trajectory'] = df.loc[df.index.isin(anomalous_indices), 'Parsed_Trajectory'].apply(lambda traj: generate_anomalous_trajectory(traj, threshold=0.9))\n",
    "\n",
    "# Create a copy of the filtered DataFrame for anomalous trajectories\n",
    "df_anomalous = df[df.index.isin(anomalous_indices)].copy()\n",
    "\n",
    "# Recalculate Distance, Duration, and Speed for each anomalous trajectory\n",
    "df_anomalous['Distance(km)'] = df_anomalous['Parsed_Trajectory'].apply(calculate_trajectory_distance)  # in kilometers\n",
    "df_anomalous['Duration(hr)'] = (pd.to_datetime(df_anomalous['End Time']) - pd.to_datetime(df_anomalous['Start Time'])).dt.total_seconds() / 3600 # in hours\n",
    "df_anomalous['Speed(km/h)'] = df_anomalous['Distance(km)'] / df_anomalous['Duration(hr)'] # in km/hr\n",
    "\n",
    "# Add Anomalous column with value 1\n",
    "df_anomalous['Anomalous'] = 1\n",
    "\n",
    "# Drop the Parsed_Trajectory column\n",
    "df_anomalous.drop(columns=['Parsed_Trajectory'], inplace=True)\n",
    "\n",
    "# Print df_anomalous DataFrame\n",
    "print(df_anomalous)\n",
    "\n",
    "# Save df_anomalous DataFrame to generated_anomalous_trajectories.csv file\n",
    "output_file_path = os.path.join(main_directory, 'generated_anomalous_trajectories.csv')\n",
    "df_anomalous.to_csv(output_file_path, index=False)\n",
    "print(f\"Anomalous trajectories saved to {output_file_path}\")\n",
    "\n",
    "# Print the total number of anomalous trajectories generated\n",
    "print(f\"Total number of anomalous trajectories generated: {len(anomalous_indices)}\")\n",
    "\n",
    "# Print the count of anomalous trajectories generated for each mode of transport\n",
    "anomalous_modes_count = df_anomalous['Transportation Mode'].value_counts()\n",
    "print(\"\\nCount of anomalous trajectories generated for each mode of transport:\")\n",
    "print(anomalous_modes_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c15924-7b68-415b-8958-7df8febbd837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3 Combine Original & Generated Anomalous Trajectories (merged_trajectories.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ae2f26-33c5-4711-9dae-30a735dd3a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with zero or negative Duration(hr): 0\n",
      "Number of records with zero or negative Distance(km): 1\n",
      "Number of records with zero or negative Speed(km/h): 1\n",
      "       User Transportation Mode            Date-Time  Altitude(ft)  \\\n",
      "0        10               Train  2008-03-28 14:54:40   -777.000000   \n",
      "1        10               Train  2008-03-28 16:00:01   -777.000000   \n",
      "2        10               Train  2008-03-29 01:32:52   -777.000000   \n",
      "3        10               Train  2008-03-29 16:00:48   -777.000000   \n",
      "4        10               Train  2008-03-30 16:00:39   -777.000000   \n",
      "...     ...                 ...                  ...           ...   \n",
      "59712   172                 Car  2008-06-28 05:03:23     95.100000   \n",
      "59713   172                Walk  2008-07-18 11:14:30     98.400000   \n",
      "59714   172                Walk  2008-07-18 11:14:40     98.400000   \n",
      "59715   176                Bike  2007-11-30 09:33:10    272.309711   \n",
      "59716   181                Walk  2007-12-07 10:06:05    226.377953   \n",
      "\n",
      "               Start Time            End Time  Start Latitude(deg)  \\\n",
      "0     2008-03-28 14:52:54 2008-03-28 15:59:59            39.894178   \n",
      "1     2008-03-28 16:00:00 2008-03-28 22:02:00            39.502930   \n",
      "2     2008-03-29 01:27:50 2008-03-29 15:59:59            36.663282   \n",
      "3     2008-03-29 16:00:00 2008-03-30 15:59:59            34.497127   \n",
      "4     2008-03-30 16:00:00 2008-03-31 03:13:11            41.147205   \n",
      "...                   ...                 ...                  ...   \n",
      "59712 2008-06-28 04:39:37 2008-06-28 12:22:03            39.021020   \n",
      "59713 2008-07-18 10:16:30 2008-07-18 10:24:50            39.976136   \n",
      "59714 2008-07-18 10:21:32 2008-07-18 10:24:50            39.975943   \n",
      "59715 2007-11-29 02:02:53 2007-11-29 14:21:00            39.966713   \n",
      "59716 2007-11-29 22:19:39 2007-11-30 06:34:04            39.952737   \n",
      "\n",
      "       Start Longitude(deg)  End Latitude(deg)  End Longitude(deg)  \\\n",
      "0                116.318200          39.506952          116.707353   \n",
      "1                116.714948          36.671463          116.988268   \n",
      "2                116.959467          34.490502          109.629697   \n",
      "3                109.619872          41.137635           95.465557   \n",
      "4                 95.457762          43.697033           87.576190   \n",
      "...                     ...                ...                 ...   \n",
      "59712            116.462773          39.973525          116.330967   \n",
      "59713            116.331999          39.975914          116.330915   \n",
      "59714            116.332456          39.975914          116.330915   \n",
      "59715            116.344933          39.976255          116.330807   \n",
      "59716            116.389118          39.953342          116.342175   \n",
      "\n",
      "                                              Trajectory  Distance(km)  \\\n",
      "0      LINESTRING (116.3182 39.894178, 116.321132 39....     62.604343   \n",
      "1      LINESTRING (116.714948 39.50293, 116.726137 39...    409.116643   \n",
      "2      LINESTRING (116.959467 36.663282, 116.956267 3...   1071.454161   \n",
      "3      LINESTRING (109.619872 34.497127, 109.6054 34....   1588.784518   \n",
      "4      LINESTRING (95.457762 41.147205, 95.444897 41....    772.508295   \n",
      "...                                                  ...           ...   \n",
      "59712  LINESTRING (-149.0629233 60.8465016, -149.0621...     83.448942   \n",
      "59713  LINESTRING (116.3312366 39.9881233, 116.331213...      0.612515   \n",
      "59714  LINESTRING (116.331305 39.9880783, 116.3313149...      0.419669   \n",
      "59715  LINESTRING (116.330216666667 39.9762, 116.3303...      4.685983   \n",
      "59716  LINESTRING (116.330266666667 39.9761, 116.331 ...     39.180458   \n",
      "\n",
      "       Duration(hr)  Speed(km/h)  Anomalous  \n",
      "0          1.118056    55.993947          0  \n",
      "1          6.033333    67.809388          0  \n",
      "2         14.535833    73.711230          0  \n",
      "3         23.999722    66.200121          0  \n",
      "4         11.219722    68.852711          0  \n",
      "...             ...          ...        ...  \n",
      "59712      7.707222    10.827369          1  \n",
      "59713      0.138889     4.410105          1  \n",
      "59714      0.055000     7.630342          1  \n",
      "59715     12.301944     0.380914          1  \n",
      "59716      8.240278     4.754750          1  \n",
      "\n",
      "[59706 rows x 15 columns]\n",
      "Merged dataset saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\merged_trajectories.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load original combined trajectories dataset\n",
    "combined_file = os.path.join(main_directory, 'combined_trajectories_predictions.csv')\n",
    "combined_df = pd.read_csv(combined_file, parse_dates=['Start Time', 'End Time'])\n",
    "\n",
    "# Add Anomalous column to original combined_df and set its value to 0\n",
    "combined_df['Anomalous'] = 0\n",
    "\n",
    "# Load generated anomalous trajectories\n",
    "anomalous_file = os.path.join(main_directory, 'generated_anomalous_trajectories.csv')\n",
    "anomalous_df = pd.read_csv(anomalous_file, parse_dates=['Start Time', 'End Time'])\n",
    "\n",
    "# Combine trajectories\n",
    "merged_df = pd.concat([combined_df, anomalous_df], ignore_index=True)\n",
    "\n",
    "# Check for negative values in the Duration(hr) column and return the count\n",
    "negative_duration_count = (df['Duration(hr)'] <= 0).sum()\n",
    "print(f\"Number of records with zero or negative Duration(hr): {negative_duration_count}\")\n",
    "\n",
    "# Check for negative values in the Distance(km) column and return the count\n",
    "negative_distance_count = (df['Distance(km)'] <= 0).sum()\n",
    "print(f\"Number of records with zero or negative Distance(km): {negative_distance_count}\")\n",
    "\n",
    "# Check for negative values in the Speed(km/h) column and return the count\n",
    "negative_speed_count = (df['Speed(km/h)'] <= 0).sum()\n",
    "print(f\"Number of records with zero or negative Speed(km/h): {negative_speed_count}\")\n",
    "\n",
    "# Remove records with negative or zero speed\n",
    "merged_df = merged_df[merged_df['Duration(hr)'] > 0]\n",
    "\n",
    "# Remove records with negative or zero speed\n",
    "merged_df = merged_df[merged_df['Distance(km)'] > 0]\n",
    "\n",
    "# Remove records with negative or zero speed\n",
    "merged_df = merged_df[merged_df['Speed(km/h)'] > 0]\n",
    "\n",
    "# Print merged_df DataFrame\n",
    "print(merged_df)\n",
    "\n",
    "# Save merged_df dataframe to merged_trajectories.csv file\n",
    "output_merged_file = os.path.join(main_directory, 'merged_trajectories.csv')\n",
    "merged_df.to_csv(output_merged_file, index=False)\n",
    "print(f\"Merged dataset saved to {output_merged_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a4d2ae-29b9-451f-a8a5-707a489f5eb8",
   "metadata": {},
   "source": [
    "# 5. Model to Detect Anomalies in Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c705f6-ee3d-4115-803c-82137515ee57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.1 Train & Evaluate Model - Combined Model: XGBoost, IsolationForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1fbfde3-04b8-4475-b784-5bdb946d24f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wengk.WK\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Anomalies Detected: 491\n",
      "Number of Anomalies Generated: 567\n",
      "Detection Percentage: 86.59611992945327%\n",
      "       User  Transportation Mode            Date-Time  Altitude(ft)  \\\n",
      "0        22                    1  2009-05-07 16:19:24         181.0   \n",
      "1         0                    4  2009-07-04 04:31:25          14.0   \n",
      "2       163                    4  2008-06-22 12:47:01           3.3   \n",
      "3         8                    3  2008-11-19 08:22:23          94.0   \n",
      "4         1                    4  2008-10-24 05:33:53         196.0   \n",
      "...     ...                  ...                  ...           ...   \n",
      "11937    84                    3  2008-10-25 09:57:02         494.0   \n",
      "11938    25                    4  2009-06-18 07:19:33         269.0   \n",
      "11939   112                    4  2008-06-11 16:01:27         154.2   \n",
      "11940    70                    3  2008-09-28 07:22:40         120.0   \n",
      "11941    23                    4  2009-01-17 03:08:49           0.0   \n",
      "\n",
      "       Start Time    End Time  Start Latitude(deg)  Start Longitude(deg)  \\\n",
      "0      1241690265  1241691489            39.957263            116.331479   \n",
      "1      1246669360  1246687089            40.022059            116.368568   \n",
      "2      1214138299  1214140273            39.975207            116.328543   \n",
      "3      1227096139  1227098583            39.975635            116.331475   \n",
      "4      1224827359  1224827836            39.972937            116.350466   \n",
      "...           ...         ...                  ...                   ...   \n",
      "11937  1224928622  1224928812            39.959782            116.340431   \n",
      "11938  1245300374  1245319147            39.980588            116.353108   \n",
      "11939  1213200087  1213200938            39.975667            116.330872   \n",
      "11940  1222587562  1222588648            33.171419            107.493423   \n",
      "11941  1232161610  1232167470            40.292004            116.664095   \n",
      "\n",
      "       End Latitude(deg)  End Longitude(deg)  \\\n",
      "0              39.986572          116.359254   \n",
      "1              40.065581          116.405701   \n",
      "2              39.975453          116.329787   \n",
      "3              40.076822          116.325568   \n",
      "4              39.980806          116.352788   \n",
      "...                  ...                 ...   \n",
      "11937          39.975466          116.334263   \n",
      "11938          39.977533          116.360144   \n",
      "11939          39.972068          116.324998   \n",
      "11940          33.829624          108.394704   \n",
      "11941          40.292537          116.664570   \n",
      "\n",
      "                                              Trajectory  Distance(km)  \\\n",
      "0      LINESTRING (116.304419 39.971402, 116.304509 3...      4.027774   \n",
      "1      LINESTRING (116.320675 40.007611, 116.320395 4...      5.780325   \n",
      "2      LINESTRING (116.3285433 39.9752066, 116.328468...      0.181707   \n",
      "3      LINESTRING (116.325945 39.980015, 116.325664 3...     11.262682   \n",
      "4      LINESTRING (116.31535 39.97968, 116.315218 39....      0.897123   \n",
      "...                                                  ...           ...   \n",
      "11937  LINESTRING (116.340431 39.959782, 116.339879 3...      1.873474   \n",
      "11938  LINESTRING (116.3120416 39.97368, 116.3121616 ...      0.185742   \n",
      "11939  LINESTRING (116.3308716 39.9756666, 116.330871...      1.298180   \n",
      "11940  LINESTRING (116.483508 39.904034, 116.483503 3...     38.921851   \n",
      "11941  LINESTRING (111.764718333333 26.6638866666667,...     89.058276   \n",
      "\n",
      "       Duration(hr)  Speed(km/h)  Anomalous  \\\n",
      "0          0.339945    11.848303          0   \n",
      "1          4.924766     1.173726          0   \n",
      "2          0.548333     0.331381          0   \n",
      "3          0.678889    16.589876          0   \n",
      "4          0.132456     6.773015          0   \n",
      "...             ...          ...        ...   \n",
      "11937      0.052778    35.497394          1   \n",
      "11938      5.214722     0.035619          1   \n",
      "11939      0.236389     5.491712          1   \n",
      "11940      0.301667   129.022709          1   \n",
      "11941      1.627778    54.711569          1   \n",
      "\n",
      "                                       Parsed Trajectory  \n",
      "0      LINESTRING (116.304419 39.971402, 116.304509 3...  \n",
      "1      LINESTRING (116.320675 40.007611, 116.320395 4...  \n",
      "2      LINESTRING (116.3285433 39.9752066, 116.328468...  \n",
      "3      LINESTRING (116.325945 39.980015, 116.325664 3...  \n",
      "4      LINESTRING (116.31535 39.97968, 116.315218 39....  \n",
      "...                                                  ...  \n",
      "11937  LINESTRING (116.340431 39.959782, 116.339879 3...  \n",
      "11938  LINESTRING (116.3120416 39.97368, 116.3121616 ...  \n",
      "11939  LINESTRING (116.3308716 39.9756666, 116.330871...  \n",
      "11940  LINESTRING (116.483508 39.904034, 116.483503 3...  \n",
      "11941  LINESTRING (111.764718333333 26.6638866666667,...  \n",
      "\n",
      "[11942 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from shapely.geometry import LineString\n",
    "import joblib\n",
    "\n",
    "# Load merged dataset\n",
    "merged_file = os.path.join(main_directory, 'merged_trajectories.csv')\n",
    "merged_df = pd.read_csv(merged_file, parse_dates=['Start Time', 'End Time'])\n",
    "\n",
    "# Split dataset into normal and anomalous\n",
    "normal_df = merged_df[merged_df['Anomalous'] == 0]\n",
    "anomalous_df = merged_df[merged_df['Anomalous'] == 1]\n",
    "\n",
    "# Split datasets into training and testing sets\n",
    "normal_train, normal_test = train_test_split(normal_df, test_size=0.2, random_state=42)\n",
    "anomalous_train, anomalous_test = train_test_split(anomalous_df, test_size=0.2, random_state=42)\n",
    "train_df = pd.concat([normal_train, anomalous_train], ignore_index=True)\n",
    "test_df = pd.concat([normal_test, anomalous_test], ignore_index=True)\n",
    "\n",
    "# Function to parse each trajectory individually\n",
    "def parse_trajectories(trajectory_string):\n",
    "    # Remove 'LINESTRING (' and ')'\n",
    "    coords_str = trajectory_string.replace('LINESTRING (', '').replace(')', '')\n",
    "    \n",
    "    # Split by ', ' to get individual coordinate pairs\n",
    "    coord_pairs = coords_str.split(', ')\n",
    "    \n",
    "    if len(coord_pairs) < 2:\n",
    "        raise ValueError(f\"Insufficient coordinate pairs in LineString representation: {trajectory_string}\")\n",
    "    \n",
    "    # Extract coordinates\n",
    "    coords = []\n",
    "    for coord_pair in coord_pairs:\n",
    "        lon_lat = coord_pair.split()\n",
    "        if len(lon_lat) != 2:\n",
    "            raise ValueError(f\"Invalid coordinate pair format: {coord_pair}\")\n",
    "        lon = float(lon_lat[0])\n",
    "        lat = float(lon_lat[1])\n",
    "        coords.append((lon, lat))\n",
    "    \n",
    "    return LineString(coords)\n",
    "\n",
    "# Define features\n",
    "features = ['Distance(km)', 'Duration(hr)', 'Speed(km/h)', 'Transportation Mode', 'Start Time', 'End Time',\n",
    "            'Start Latitude(deg)', 'Start Longitude(deg)', 'End Latitude(deg)', 'End Longitude(deg)']\n",
    "\n",
    "# Preprocess training set\n",
    "le = LabelEncoder()\n",
    "train_df['Transportation Mode'] = le.fit_transform(train_df['Transportation Mode'])\n",
    "train_df['Start Time'] = pd.to_datetime(train_df['Start Time']).astype(np.int64) // 10**9\n",
    "train_df['End Time'] = pd.to_datetime(train_df['End Time']).astype(np.int64) // 10**9\n",
    "train_df['Parsed Trajectory'] = train_df['Trajectory'].apply(parse_trajectories)\n",
    "\n",
    "# Initialize & perform Grid Search for XGBoost Model\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [12],\n",
    "    'learning_rate': [0.3],\n",
    "    'colsample_bytree': [0.9],\n",
    "    'subsample': [1.0],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_grid = GridSearchCV(xgb_model, param_grid_xgb, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid.fit(train_df[features], train_df['Anomalous'])\n",
    "\n",
    "# Initialize & perform Grid Search for Isolation Forest Model\n",
    "param_grid_if = {\n",
    "    'n_estimators': [300],\n",
    "    'max_samples': [2],\n",
    "    'contamination': [0.1]\n",
    "}\n",
    "\n",
    "iso_forest = IsolationForest(random_state=42)\n",
    "if_grid = GridSearchCV(iso_forest, param_grid_if, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "if_grid.fit(train_df[features])\n",
    "\n",
    "# Save both models\n",
    "xgb_model_file_path = os.path.join(main_directory, 'xgb_model.pkl')\n",
    "joblib.dump(xgb_grid.best_estimator_, xgb_model_file_path)\n",
    "\n",
    "iso_forest_file_path = os.path.join(main_directory, 'iso_forest_model.pkl')\n",
    "joblib.dump(if_grid.best_estimator_, iso_forest_file_path)\n",
    "\n",
    "# Preprocess testing set\n",
    "test_df['Transportation Mode'] = le.transform(test_df['Transportation Mode'])\n",
    "test_df['Start Time'] = pd.to_datetime(test_df['Start Time']).astype(np.int64) // 10**9\n",
    "test_df['End Time'] = pd.to_datetime(test_df['End Time']).astype(np.int64) // 10**9\n",
    "test_df['Parsed Trajectory'] = test_df['Trajectory'].apply(parse_trajectories)\n",
    "\n",
    "# Predict anomalies\n",
    "test_df['XGB_Predicted_Anomaly'] = xgb_grid.best_estimator_.predict(test_df[features])\n",
    "test_df['IF_Predicted_Anomaly'] = if_grid.best_estimator_.predict(test_df[features])\n",
    "test_df['IF_Predicted_Anomaly'] = test_df['IF_Predicted_Anomaly'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# Combine predictions using weighted voting\n",
    "weights = {'XGB': 0.6, 'IF': 0.4}\n",
    "test_df['Weighted_Predicted_Anomaly'] = np.zeros(len(test_df))\n",
    "for model, preds in {\n",
    "    'XGB': test_df['XGB_Predicted_Anomaly'],\n",
    "    'IF': test_df['IF_Predicted_Anomaly']\n",
    "}.items():\n",
    "    test_df['Weighted_Predicted_Anomaly'] += weights[model] * preds\n",
    "\n",
    "# Apply a threshold to determine final anomaly prediction\n",
    "threshold = 0.5\n",
    "test_df['Final_Predicted_Anomaly'] = (test_df['Weighted_Predicted_Anomaly'] > threshold).astype(int)\n",
    "\n",
    "# Significant Variations in Speed or Duration\n",
    "speed_threshold = 350  # in km/h\n",
    "duration_threshold = 24  # in hours (1 day)\n",
    "\n",
    "def detect_variation_anomalies(row):\n",
    "    if row['Speed(km/h)'] > speed_threshold or row['Duration(hr)'] > duration_threshold:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "test_df['Variation_Anomaly'] = test_df.apply(detect_variation_anomalies, axis=1)\n",
    "\n",
    "# Combine all anomaly detections\n",
    "test_df['Combined_Anomaly'] = np.maximum(test_df['Final_Predicted_Anomaly'], test_df['Variation_Anomaly'])\n",
    "\n",
    "# Calculate the number of detected and generated anomalies\n",
    "num_detected_anomalies = test_df['Combined_Anomaly'].sum()\n",
    "num_anomalies_generated = test_df['Anomalous'].sum()\n",
    "\n",
    "# Calculate the detection percentage\n",
    "detection_percentage = (num_detected_anomalies / num_anomalies_generated) * 100 \n",
    "\n",
    "print(f\"Number of Anomalies Detected: {num_detected_anomalies}\")\n",
    "print(f\"Number of Anomalies Generated: {num_anomalies_generated}\")\n",
    "print(f\"Detection Percentage: {detection_percentage:}%\")\n",
    "\n",
    "# Drop columns related to anomalies\n",
    "columns_to_drop = [col for col in test_df.columns if 'Anomaly' in col]\n",
    "test_df = test_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Print the final dataframe\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a3cc2-ab6d-4724-a5fb-86631d25e2c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.2 Detect Anomalies in Merged Dataset with Generated Anomalies (use merged_trajectories.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7c5206-66b5-4382-ac03-4b2cc2272143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records dropped due to NA values: 0\n",
      "Number of anomalies detected: 2964\n",
      "Percentage of dataset that are anomalous: 4.964%\n",
      "Anomalous records:\n",
      "       User Transportation Mode            Date-Time  Altitude(ft)  \\\n",
      "198      10                Walk  2008-09-26 12:50:33     16.000000   \n",
      "322      10               Train  2008-10-09 23:10:30     92.000000   \n",
      "353      10                 Car  2008-10-16 00:01:50    135.000000   \n",
      "407      10                Walk  2008-11-07 05:24:51    430.000000   \n",
      "423      10                 Car  2008-12-07 10:19:25     10.000000   \n",
      "...     ...                 ...                  ...           ...   \n",
      "59699   172                 Bus  2008-06-27 02:02:12    187.000000   \n",
      "59700   172                 Car  2008-06-27 02:05:36    187.000000   \n",
      "59701   172                 Car  2008-06-28 05:03:23     95.100000   \n",
      "59703   172                Walk  2008-07-18 11:14:40     98.400000   \n",
      "59704   176                Bike  2007-11-30 09:33:10    272.309711   \n",
      "\n",
      "               Start Time            End Time  Start Latitude(deg)  \\\n",
      "198   2008-09-26 12:50:33 2008-09-26 12:55:00            39.164978   \n",
      "322   2008-10-09 23:09:35 2008-10-09 23:40:03            39.138638   \n",
      "353   2008-10-16 00:01:50 2008-10-16 00:24:07            39.863530   \n",
      "407   2008-11-07 05:24:51 2008-11-07 05:29:35            39.993574   \n",
      "423   2008-12-07 10:19:25 2008-12-07 10:21:54            39.136331   \n",
      "...                   ...                 ...                  ...   \n",
      "59699 2008-06-27 01:50:47 2008-06-27 02:12:20            39.665644   \n",
      "59700 2008-06-27 01:56:56 2008-06-27 02:12:20            39.773812   \n",
      "59701 2008-06-28 04:39:37 2008-06-28 12:22:03            39.021020   \n",
      "59703 2008-07-18 10:21:32 2008-07-18 10:24:50            39.975943   \n",
      "59704 2007-11-29 02:02:53 2007-11-29 14:21:00            39.966713   \n",
      "\n",
      "       Start Longitude(deg)  End Latitude(deg)  End Longitude(deg)  ...  \\\n",
      "198              117.203778          39.164846          117.202808  ...   \n",
      "322              117.199466          39.863599          116.374116  ...   \n",
      "353              116.368988          39.893759          116.368375  ...   \n",
      "407              116.325821          39.996986          116.329885  ...   \n",
      "423              117.208321          39.136349          117.218319  ...   \n",
      "...                     ...                ...                 ...  ...   \n",
      "59699            115.301298          39.982503          116.371548  ...   \n",
      "59700            115.681746          39.982503          116.371548  ...   \n",
      "59701            116.462773          39.973525          116.330967  ...   \n",
      "59703            116.332456          39.975914          116.330915  ...   \n",
      "59704            116.344933          39.976255          116.330807  ...   \n",
      "\n",
      "      Distance(km)  Duration(hr)  Speed(km/h)  \\\n",
      "198       0.385762      0.074167     5.201279   \n",
      "322     111.647854      0.507778   219.875423   \n",
      "353       3.572293      0.371389     9.618740   \n",
      "407       0.575545      0.078889     7.295645   \n",
      "423       1.031263      0.041389    24.916411   \n",
      "...            ...           ...          ...   \n",
      "59699     2.290570      0.359167     6.377458   \n",
      "59700     0.960981      0.256667     3.744082   \n",
      "59701    83.448942      7.707222    10.827369   \n",
      "59703     0.419669      0.055000     7.630342   \n",
      "59704     4.685983     12.301944     0.380914   \n",
      "\n",
      "                                       Parsed Trajectory  \\\n",
      "198    LINESTRING (117.203778 39.164978, 117.20378 39...   \n",
      "322    LINESTRING (117.199466 39.138638, 117.199376 3...   \n",
      "353    LINESTRING (116.368988 39.86353, 116.368971 39...   \n",
      "407    LINESTRING (116.325821 39.993574, 116.325821 3...   \n",
      "423    LINESTRING (117.208321 39.136331, 117.208368 3...   \n",
      "...                                                  ...   \n",
      "59699  LINESTRING (-150.0628766 61.7599299, -150.0630...   \n",
      "59700  LINESTRING (-150.0991433 61.8050066, -150.0990...   \n",
      "59701  LINESTRING (-149.0629233 60.8465016, -149.0621...   \n",
      "59703  LINESTRING (116.331305 39.9880783, 116.3313149...   \n",
      "59704  LINESTRING (116.330216666667 39.9762, 116.3303...   \n",
      "\n",
      "      XGB_Predicted_Anomaly  IF_Predicted_Anomaly  Weighted_Predicted_Anomaly  \\\n",
      "198                       1                     0                         0.6   \n",
      "322                       1                     0                         0.6   \n",
      "353                       1                     0                         0.6   \n",
      "407                       1                     0                         0.6   \n",
      "423                       1                     0                         0.6   \n",
      "...                     ...                   ...                         ...   \n",
      "59699                     1                     0                         0.6   \n",
      "59700                     1                     0                         0.6   \n",
      "59701                     1                     0                         0.6   \n",
      "59703                     1                     0                         0.6   \n",
      "59704                     1                     0                         0.6   \n",
      "\n",
      "       Final_Predicted_Anomaly  Variation_Anomaly  Combined_Anomaly  \n",
      "198                          1                  0                 1  \n",
      "322                          1                  0                 1  \n",
      "353                          1                  0                 1  \n",
      "407                          1                  0                 1  \n",
      "423                          1                  0                 1  \n",
      "...                        ...                ...               ...  \n",
      "59699                        1                  0                 1  \n",
      "59700                        1                  0                 1  \n",
      "59701                        1                  0                 1  \n",
      "59703                        1                  0                 1  \n",
      "59704                        1                  0                 1  \n",
      "\n",
      "[2964 rows x 21 columns]\n",
      "Merged trajectories with predicted anomalies saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\merged_trajectories_anomalies_detection.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from shapely.geometry import LineString\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define the functions for contextual anomaly detection\n",
    "def parse_trajectories(trajectory_string):\n",
    "    coords_str = trajectory_string.replace('LINESTRING (', '').replace(')', '')\n",
    "    coord_pairs = coords_str.split(', ')\n",
    "    if len(coord_pairs) < 2:\n",
    "        raise ValueError(f\"Insufficient coordinate pairs in LineString representation: {trajectory_string}\")\n",
    "    coords = [(float(pair.split()[0]), float(pair.split()[1])) for pair in coord_pairs]\n",
    "    return LineString(coords)\n",
    "\n",
    "# Significant Variations in Speed or Duration\n",
    "speed_threshold = 350  # in km/h\n",
    "duration_threshold = 24  # in hours (1 day)\n",
    "\n",
    "def detect_variation_anomalies(row):\n",
    "    if row['Speed(km/h)'] > speed_threshold or row['Duration(hr)'] > duration_threshold:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Load the merged trajectories dataset\n",
    "file_path = os.path.join(main_directory, 'merged_trajectories.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'Anomalous' column\n",
    "df = df.drop(columns=['Anomalous'])\n",
    "\n",
    "# Define the features\n",
    "features = ['Distance(km)', 'Duration(hr)', 'Speed(km/h)', 'Transportation Mode', 'Start Time', 'End Time',\n",
    "            'Start Latitude(deg)', 'Start Longitude(deg)', 'End Latitude(deg)', 'End Longitude(deg)']\n",
    "\n",
    "# Initialize the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Convert Transportation Mode to numeric values using label encoder\n",
    "df['Transportation Mode'] = le.fit_transform(df['Transportation Mode'])\n",
    "\n",
    "# Convert Start Time and End Time to numeric values (timestamp)\n",
    "df['Start Time'] = pd.to_datetime(df['Start Time']).astype(np.int64) // 10**9\n",
    "df['End Time'] = pd.to_datetime(df['End Time']).astype(np.int64) // 10**9\n",
    "\n",
    "# Check for missing or infinite values\n",
    "initial_record_count = len(df)\n",
    "\n",
    "for feature in features:\n",
    "    df[feature] = pd.to_numeric(df[feature], errors='coerce')  # Convert to numeric, forcing errors to NaN\n",
    "df = df.replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "df = df.dropna(subset=features)  # Drop rows with NaN in feature columns\n",
    "\n",
    "# Record count after dropping NA values\n",
    "record_count_after_dropping_na = len(df)\n",
    "records_dropped = initial_record_count - record_count_after_dropping_na\n",
    "print(f\"Number of records dropped due to NA values: {records_dropped}\")\n",
    "\n",
    "# Load the trained models\n",
    "xgb_model_file_path = os.path.join(main_directory, 'xgb_model.pkl')\n",
    "iso_forest_file_path = os.path.join(main_directory, 'iso_forest_model.pkl')\n",
    "\n",
    "xgb_model = joblib.load(xgb_model_file_path)\n",
    "iso_forest = joblib.load(iso_forest_file_path)\n",
    "\n",
    "# Parse trajectories for contextual anomaly detection\n",
    "df['Parsed Trajectory'] = df['Trajectory'].apply(parse_trajectories)\n",
    "\n",
    "# Predict anomalies with both models\n",
    "df['XGB_Predicted_Anomaly'] = xgb_model.predict(df[features])\n",
    "df['IF_Predicted_Anomaly'] = iso_forest.predict(df[features])\n",
    "df['IF_Predicted_Anomaly'] = df['IF_Predicted_Anomaly'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# Define weights for each model\n",
    "weights = {'XGB': 0.6, 'IF': 0.4}\n",
    "\n",
    "# Combine predictions using weighted voting\n",
    "df['Weighted_Predicted_Anomaly'] = np.zeros(len(df))\n",
    "for model, preds in {\n",
    "    'XGB': df['XGB_Predicted_Anomaly'],\n",
    "    'IF': df['IF_Predicted_Anomaly']\n",
    "}.items():\n",
    "    df['Weighted_Predicted_Anomaly'] += weights[model] * preds\n",
    "\n",
    "# Apply a threshold to determine final anomaly prediction\n",
    "threshold = 0.5\n",
    "df['Final_Predicted_Anomaly'] = (df['Weighted_Predicted_Anomaly'] > threshold).astype(int)\n",
    "\n",
    "df['Variation_Anomaly'] = df.apply(detect_variation_anomalies, axis=1)\n",
    "\n",
    "# Combine all anomaly detections\n",
    "df['Combined_Anomaly'] = np.maximum(df['Final_Predicted_Anomaly'], df['Variation_Anomaly'])\n",
    "\n",
    "# Convert Start & End Time and Transportation Mode back to their original forms\n",
    "df['Transportation Mode'] = le.inverse_transform(df['Transportation Mode'])\n",
    "df['Start Time'] = pd.to_datetime(df['Start Time'], unit='s')\n",
    "df['End Time'] = pd.to_datetime(df['End Time'], unit='s')\n",
    "\n",
    "# Print number of anomalies detected\n",
    "num_anomalies = df['Combined_Anomaly'].sum()\n",
    "print(f\"Number of anomalies detected: {num_anomalies}\")\n",
    "\n",
    "# Print percentage of dataset that is anomaly\n",
    "total_records = len(df)\n",
    "percentage_anomalies = (num_anomalies / total_records) * 100\n",
    "print(f\"Percentage of dataset that are anomalous: {percentage_anomalies:.3f}%\")\n",
    "\n",
    "# Filter and print anomalous records\n",
    "anomalous_records = df[df['Combined_Anomaly'] == 1]\n",
    "print(\"Anomalous records:\")\n",
    "print(anomalous_records)\n",
    "\n",
    "# Save the dataset with predicted anomalies to a new CSV file\n",
    "output_file_path = os.path.join(main_directory, 'merged_trajectories_anomalies_detection.csv')\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Merged trajectories with predicted anomalies saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8915529-21f6-4043-9e30-3f831e1d232c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.3 Detect Anomalies in Combined Dataset w/o Generated Anomalies (use combined_trajectories_predictions.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f40e32c-4609-45fe-9396-a3a62c31709c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records dropped due to NA values: 0\n",
      "Number of anomalies detected: 679\n",
      "Percentage of dataset that are anomalous: 1.194%\n",
      "Anomalous records:\n",
      "       User Transportation Mode            Date-Time  Altitude(ft)  \\\n",
      "198      10                Walk  2008-09-26 12:50:33      16.00000   \n",
      "322      10               Train  2008-10-09 23:10:30      92.00000   \n",
      "353      10                 Car  2008-10-16 00:01:50     135.00000   \n",
      "407      10                Walk  2008-11-07 05:24:51     430.00000   \n",
      "423      10                 Car  2008-12-07 10:19:25      10.00000   \n",
      "...     ...                 ...                  ...           ...   \n",
      "55979   142                Walk  2011-01-22 08:53:21     106.00000   \n",
      "56112   146                 Car  2007-08-01 14:19:12     311.67979   \n",
      "56214   152                 Car  2008-08-23 03:10:56      81.00000   \n",
      "56711   168                Walk  2011-08-17 22:40:53     528.00000   \n",
      "56783   172                 Car  2008-06-27 05:19:25     387.10000   \n",
      "\n",
      "               Start Time            End Time  Start Latitude(deg)  \\\n",
      "198   2008-09-26 12:50:33 2008-09-26 12:55:00            39.164978   \n",
      "322   2008-10-09 23:09:35 2008-10-09 23:40:03            39.138638   \n",
      "353   2008-10-16 00:01:50 2008-10-16 00:24:07            39.863530   \n",
      "407   2008-11-07 05:24:51 2008-11-07 05:29:35            39.993574   \n",
      "423   2008-12-07 10:19:25 2008-12-07 10:21:54            39.136331   \n",
      "...                   ...                 ...                  ...   \n",
      "55979 2011-01-25 13:00:52 2011-01-27 18:32:35            39.977289   \n",
      "56112 2007-07-30 05:05:17 2007-07-30 05:05:49            39.946795   \n",
      "56214 2008-08-23 03:20:05 2008-08-23 03:20:21            39.998803   \n",
      "56711 2011-08-12 14:39:26 2011-08-12 17:33:08            39.978114   \n",
      "56783 2008-06-27 05:34:11 2008-06-27 05:44:26            39.908305   \n",
      "\n",
      "       Start Longitude(deg)  End Latitude(deg)  End Longitude(deg)  ...  \\\n",
      "198              117.203778          39.164846          117.202808  ...   \n",
      "322              117.199466          39.863599          116.374116  ...   \n",
      "353              116.368988          39.893759          116.368375  ...   \n",
      "407              116.325821          39.996986          116.329885  ...   \n",
      "423              117.208321          39.136349          117.218319  ...   \n",
      "...                     ...                ...                 ...  ...   \n",
      "55979            116.423313          39.975656          116.430647  ...   \n",
      "56112            116.367394          39.973542          116.330662  ...   \n",
      "56214            116.342366          39.988400          116.327133  ...   \n",
      "56711            116.324856          39.976737          116.332416  ...   \n",
      "56783            116.148045          38.928262          112.957056  ...   \n",
      "\n",
      "      Distance(km)  Duration(hr)  Speed(km/h)  \\\n",
      "198       0.385762      0.074167     5.201279   \n",
      "322     111.647854      0.507778   219.875423   \n",
      "353       3.572293      0.371389     9.618740   \n",
      "407       0.575545      0.078889     7.295645   \n",
      "423       1.031263      0.041389    24.916411   \n",
      "...            ...           ...          ...   \n",
      "55979     0.650770     53.528704     0.012157   \n",
      "56112     4.318205      0.009139   472.508733   \n",
      "56214     1.738433      0.004202   413.681931   \n",
      "56711     0.662122      2.894881     0.228722   \n",
      "56783   294.956124      0.171012  1724.772647   \n",
      "\n",
      "                                       Parsed Trajectory  \\\n",
      "198    LINESTRING (117.203778 39.164978, 117.20378 39...   \n",
      "322    LINESTRING (117.199466 39.138638, 117.199376 3...   \n",
      "353    LINESTRING (116.368988 39.86353, 116.368971 39...   \n",
      "407    LINESTRING (116.325821 39.993574, 116.325821 3...   \n",
      "423    LINESTRING (117.208321 39.136331, 117.208368 3...   \n",
      "...                                                  ...   \n",
      "55979  LINESTRING (116.440606 39.961294, 116.440711 3...   \n",
      "56112  LINESTRING (116.3275 39.9729166666667, 116.327...   \n",
      "56214  LINESTRING (116.315649 40.004528, 116.315628 4...   \n",
      "56711  LINESTRING (116.405958 40.063404, 116.40601 40...   \n",
      "56783  LINESTRING (-150.0982449 62.3213016, -150.0982...   \n",
      "\n",
      "      XGB_Predicted_Anomaly  IF_Predicted_Anomaly  Weighted_Predicted_Anomaly  \\\n",
      "198                       1                     0                         0.6   \n",
      "322                       1                     0                         0.6   \n",
      "353                       1                     0                         0.6   \n",
      "407                       1                     0                         0.6   \n",
      "423                       1                     0                         0.6   \n",
      "...                     ...                   ...                         ...   \n",
      "55979                     0                     0                         0.0   \n",
      "56112                     0                     0                         0.0   \n",
      "56214                     0                     0                         0.0   \n",
      "56711                     1                     0                         0.6   \n",
      "56783                     0                     0                         0.0   \n",
      "\n",
      "       Final_Predicted_Anomaly  Variation_Anomaly  Combined_Anomaly  \n",
      "198                          1                  0                 1  \n",
      "322                          1                  0                 1  \n",
      "353                          1                  0                 1  \n",
      "407                          1                  0                 1  \n",
      "423                          1                  0                 1  \n",
      "...                        ...                ...               ...  \n",
      "55979                        0                  1                 1  \n",
      "56112                        0                  1                 1  \n",
      "56214                        0                  1                 1  \n",
      "56711                        1                  0                 1  \n",
      "56783                        0                  1                 1  \n",
      "\n",
      "[679 rows x 21 columns]\n",
      "Merged trajectories with predicted anomalies saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\combined_trajectories_predictions_detection.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from shapely.geometry import LineString\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define the functions for contextual anomaly detection\n",
    "def parse_trajectories(trajectory_string):\n",
    "    coords_str = trajectory_string.replace('LINESTRING (', '').replace(')', '')\n",
    "    coord_pairs = coords_str.split(', ')\n",
    "    if len(coord_pairs) < 2:\n",
    "        raise ValueError(f\"Insufficient coordinate pairs in LineString representation: {trajectory_string}\")\n",
    "    coords = [(float(pair.split()[0]), float(pair.split()[1])) for pair in coord_pairs]\n",
    "    return LineString(coords)\n",
    "\n",
    "# Significant Variations in Speed or Duration\n",
    "speed_threshold = 350  # in km/h\n",
    "duration_threshold = 24  # in hours (1 day)\n",
    "\n",
    "def detect_variation_anomalies(row):\n",
    "    if row['Speed(km/h)'] > speed_threshold or row['Duration(hr)'] > duration_threshold:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Load the merged trajectories dataset\n",
    "file_path = os.path.join(main_directory, 'combined_trajectories_predictions.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the features\n",
    "features = ['Distance(km)', 'Duration(hr)', 'Speed(km/h)', 'Transportation Mode', 'Start Time', 'End Time',\n",
    "            'Start Latitude(deg)', 'Start Longitude(deg)', 'End Latitude(deg)', 'End Longitude(deg)']\n",
    "\n",
    "# Initialize the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Convert Transportation Mode to numeric values using label encoder\n",
    "df['Transportation Mode'] = le.fit_transform(df['Transportation Mode'])\n",
    "\n",
    "# Convert Start Time and End Time to numeric values (timestamp)\n",
    "df['Start Time'] = pd.to_datetime(df['Start Time']).astype(np.int64) // 10**9\n",
    "df['End Time'] = pd.to_datetime(df['End Time']).astype(np.int64) // 10**9\n",
    "\n",
    "# Check for missing or infinite values\n",
    "initial_record_count = len(df)\n",
    "\n",
    "for feature in features:\n",
    "    df[feature] = pd.to_numeric(df[feature], errors='coerce')  # Convert to numeric, forcing errors to NaN\n",
    "df = df.replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "df = df.dropna(subset=features)  # Drop rows with NaN in feature columns\n",
    "\n",
    "# Record count after dropping NA values\n",
    "record_count_after_dropping_na = len(df)\n",
    "records_dropped = initial_record_count - record_count_after_dropping_na\n",
    "print(f\"Number of records dropped due to NA values: {records_dropped}\")\n",
    "\n",
    "# Load the trained models\n",
    "xgb_model_file_path = os.path.join(main_directory, 'xgb_model.pkl')\n",
    "iso_forest_file_path = os.path.join(main_directory, 'iso_forest_model.pkl')\n",
    "\n",
    "xgb_model = joblib.load(xgb_model_file_path)\n",
    "iso_forest = joblib.load(iso_forest_file_path)\n",
    "\n",
    "# Parse trajectories for contextual anomaly detection\n",
    "df['Parsed Trajectory'] = df['Trajectory'].apply(parse_trajectories)\n",
    "\n",
    "# Predict anomalies with both models\n",
    "df['XGB_Predicted_Anomaly'] = xgb_model.predict(df[features])\n",
    "df['IF_Predicted_Anomaly'] = iso_forest.predict(df[features])\n",
    "df['IF_Predicted_Anomaly'] = df['IF_Predicted_Anomaly'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# Define weights for each model\n",
    "weights = {'XGB': 0.6, 'IF': 0.4}\n",
    "\n",
    "# Combine predictions using weighted voting\n",
    "df['Weighted_Predicted_Anomaly'] = np.zeros(len(df))\n",
    "for model, preds in {\n",
    "    'XGB': df['XGB_Predicted_Anomaly'],\n",
    "    'IF': df['IF_Predicted_Anomaly']\n",
    "}.items():\n",
    "    df['Weighted_Predicted_Anomaly'] += weights[model] * preds\n",
    "\n",
    "# Apply a threshold to determine final anomaly prediction\n",
    "threshold = 0.5\n",
    "df['Final_Predicted_Anomaly'] = (df['Weighted_Predicted_Anomaly'] > threshold).astype(int)\n",
    "\n",
    "df['Variation_Anomaly'] = df.apply(detect_variation_anomalies, axis=1)\n",
    "\n",
    "# Combine all anomaly detections\n",
    "df['Combined_Anomaly'] = np.maximum(df['Final_Predicted_Anomaly'], df['Variation_Anomaly'])\n",
    "\n",
    "# Convert Start & End Time and Transportation Mode back to their original forms\n",
    "df['Transportation Mode'] = le.inverse_transform(df['Transportation Mode'])\n",
    "df['Start Time'] = pd.to_datetime(df['Start Time'], unit='s')\n",
    "df['End Time'] = pd.to_datetime(df['End Time'], unit='s')\n",
    "\n",
    "# Print number of anomalies detected\n",
    "num_anomalies = df['Combined_Anomaly'].sum()\n",
    "print(f\"Number of anomalies detected: {num_anomalies}\")\n",
    "\n",
    "# Print percentage of dataset that is anomaly\n",
    "total_records = len(df)\n",
    "percentage_anomalies = (num_anomalies / total_records) * 100\n",
    "print(f\"Percentage of dataset that are anomalous: {percentage_anomalies:.3f}%\")\n",
    "\n",
    "# Filter and print anomalous records\n",
    "anomalous_records = df[df['Combined_Anomaly'] == 1]\n",
    "print(\"Anomalous records:\")\n",
    "print(anomalous_records)\n",
    "\n",
    "# Save the dataset with predicted anomalies to a new CSV file\n",
    "output_file_path = os.path.join(main_directory, 'combined_trajectories_predictions_detection.csv')\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Merged trajectories with predicted anomalies saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc28ad-6bc0-483d-9fcd-bccb2c418a72",
   "metadata": {},
   "source": [
    "# 6. Plot Trajectories "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945ee6c-4212-4668-8890-418be71607d7",
   "metadata": {},
   "source": [
    "### Kepler.gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b416569b-0e6e-431d-8b9d-2f58fba3cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n",
      "Map saved to C:/Users/wengk.WK/OneDrive - Nanyang Technological University/Desktop/Anomaly Dectection In Trajectories Using GPS Data/Geolife Trajectories 1.3/Data\\trajectories_keplergl.html!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from keplergl import KeplerGl\n",
    "\n",
    "# Define file paths\n",
    "file_path = os.path.join(main_directory, 'merged_trajectories_anomalies_detection.csv')\n",
    "output_map_file = os.path.join(main_directory, 'trajectories_keplergl.html')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Sample 10% of the data\n",
    "df_sampled = df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Define colors for different transportation modes and anomalies using RGB values\n",
    "color_range = {\n",
    "    \"Walk\": [255, 0, 0], \n",
    "    \"Bike\": [0, 255, 0],  \n",
    "    \"Train\": [128, 0, 128], \n",
    "    \"Car\": [0, 0, 139],  \n",
    "    \"Bus\": [255, 255, 0],  \n",
    "    \"Anomalous\": [255, 0, 0]  \n",
    "}\n",
    "\n",
    "# Create separate DataFrames for each mode of transport and anomalies\n",
    "mode_dfs = {mode: df_sampled[df_sampled['Transportation Mode'] == mode].copy() for mode in color_range.keys() if mode != \"Anomalous\"}\n",
    "anomalous_dfs = df_sampled[df_sampled['Final_Predicted_Anomaly'] == 1].copy()\n",
    "\n",
    "# Initialize Kepler.gl map\n",
    "map_1 = KeplerGl()\n",
    "\n",
    "# Add data to the map for each mode and anomalies\n",
    "for mode, data in mode_dfs.items():\n",
    "    map_1.add_data(data=data, name=mode)\n",
    "\n",
    "# Add anomalous data\n",
    "map_1.add_data(data=anomalous_dfs, name=\"Anomalous\")\n",
    "\n",
    "# Define the configuration for the map\n",
    "config = {\n",
    "    'version': 'v1',\n",
    "    'config': {\n",
    "        'visState': {\n",
    "            'layers': [\n",
    "                {\n",
    "                    'id': f'{mode}_layer',\n",
    "                    'type': 'line',\n",
    "                    'config': {\n",
    "                        'dataId': mode,\n",
    "                        'label': f'{mode} Trajectories',\n",
    "                        'color': color_range[mode],\n",
    "                        'columns': {'geojson': 'Trajectory', 'color': 'Color'},\n",
    "                        'isVisible': True,\n",
    "                        'visConfig': {\n",
    "                            'opacity': 0.8,\n",
    "                            'thickness': 2,\n",
    "                            'colorRange': {\n",
    "                                'name': 'Custom Color Range',\n",
    "                                'type': 'custom',\n",
    "                                'colors': [color_range[mode]]\n",
    "                            },\n",
    "                            'sizeRange': [0, 10]\n",
    "                        }\n",
    "                    },\n",
    "                    'visualChannels': {\n",
    "                        'colorField': {'name': 'Color', 'type': 'rgb'},\n",
    "                        'colorScale': 'ordinal'\n",
    "                    }\n",
    "                }\n",
    "                for mode in color_range.keys() if mode != \"Anomalous\"\n",
    "            ] + [\n",
    "                {\n",
    "                    'id': 'anomalous_layer',\n",
    "                    'type': 'line',\n",
    "                    'config': {\n",
    "                        'dataId': 'Anomalous',\n",
    "                        'label': 'Anomalous Trajectories',\n",
    "                        'color': color_range[\"Anomalous\"],\n",
    "                        'columns': {'geojson': 'Trajectory', 'color': 'Color'},\n",
    "                        'isVisible': True,\n",
    "                        'visConfig': {\n",
    "                            'opacity': 0.8,\n",
    "                            'thickness': 2,\n",
    "                            'colorRange': {\n",
    "                                'name': 'Custom Color Range',\n",
    "                                'type': 'custom',\n",
    "                                'colors': [color_range[\"Anomalous\"]]\n",
    "                            },\n",
    "                            'sizeRange': [0, 10]\n",
    "                        }\n",
    "                    },\n",
    "                    'visualChannels': {\n",
    "                        'colorField': {'name': 'Color', 'type': 'rgb'},\n",
    "                        'colorScale': 'ordinal'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        'mapState': {\n",
    "            'bearing': 0,\n",
    "            'dragRotate': True,\n",
    "            'latitude': 39.9042,\n",
    "            'longitude': 116.4074,\n",
    "            'pitch': 0,\n",
    "            'zoom': 10,\n",
    "            'isSplit': False\n",
    "        },\n",
    "        'mapStyle': {\n",
    "            'styleType': 'dark',\n",
    "            'topLayerGroups': {},\n",
    "            'visibleLayerGroups': {\n",
    "                'label': True,\n",
    "                'road': True,\n",
    "                'border': False,\n",
    "                'building': True,\n",
    "                'water': True,\n",
    "                'land': True,\n",
    "                '3d building': False\n",
    "            },\n",
    "            'threeDBuildingColor': [9.665468314072013, 17.18305478057247, 31.1442867897876],\n",
    "            'mapStyles': {}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "map_1.config = config\n",
    "\n",
    "# Save the map configuration to an HTML file\n",
    "map_1.save_to_html(file_name=output_map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474b550-8c1c-4372-be53-a6cb6f2490b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
